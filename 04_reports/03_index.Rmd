---
title: 'Measuring the Statistical Performance of Countries: An Overview of the Statistical Performance Indicators and Index'
author: "SPI Team"
date: "`r Sys.Date()`"
output:
  bookdown::word_document2: 
    toc: yes
    fig_width: 9
    fig_height: 6
abstract: Recognizing the new challenges for national statistical systems in monitoring  the
  Sustainable Development Goals (SDGs), the World Bank is developing a new, improved  Statistical  Performance
  Indicators (SPI) to monitor progress of the statistical  performance  of countries.
  This will replace the Statistical Capacity Index (SCI)  the World  Bank has regularly
  published since 2004. This short note briefly discusses  the  motivation behind
  the new SPI, describes some of its major features, and discusses  a  new index based
  on the indicators.
bibliography: ./bibliography.bib
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, fig.width = 9, fig.height = 6, fig.cap = "&nbsp;", fig.path = "plots/", dev = c("png"), dpi=500)
library(tidyverse)
library(flextable)
library(here)
# devtools::install_github("worldbank/wbgviz", subdir = "wbgdata")
# devtools::install_github("worldbank/wbgviz", subdir = "wbgcharts")
# devtools::install_github("worldbank/wbgviz", subdir = "wbggeo")
# devtools::install_github("worldbank/wbgviz", subdir = "wbgmaps")
library(wbggeo)
library(wbgmaps)
library(ggthemes)
library(Hmisc)
library(httr)
library(patchwork)
library(ggrepel)
library(haven)
library(zoo)
library(estimatr)
library(ggpmisc)
library(ggthemes)
#set directories
dir <- here()

raw_dir <- paste(dir, '01_raw_data', sep="/")
output_dir <- paste(dir, '03_output_data', sep="/")

#weights (either unity (1) or population)
wgt <- 1

```

# Motivation

The primary purpose of the statistical system is to help users of statistics make better decisions or to hold those decision makers accountable. In the words of Principle 1 of the Fundamental Principles of Official Statistics, the statistics must “meet the test of practical utility”, serving “the Government, the economy and the public with data about the economic, demographic, social and environmental situation.” 

The national statistical system, or NSS, plays a crucial role in modern economies. It provides stakeholders, ranging from policy makers to stock market analysts and the general public, with the latest data on the country’s socio-economic developments. At the international level, monitoring progress on global undertakings such as the recently established Sustainable Development Goals (SDGs) requires high-quality data that must be produced consistently across different national statistical systems. Assessing and improving the capacity of a country’s NSS has long been a part of the global agenda. Since the early 2000s, a few capacity assessment tools have been developed to identify the weaknesses and strengths of national statistical systems by other organizations including PARIS21, the Food and Agriculture Organization of the United Nations (FAO), the United Nations Economic Commission for Europe (UNECE), the United Nations Economic Commission for Africa (UNECA), and the U.S. Census Bureau.   

The World Bank’s Statistical Capacity Index (SCI) is one such tool that has been widely employed. Several international and national agencies have adopted the SCI for measuring progress in statistical capacity building and related investments.   The World Bank mainstreamed the SCI in its monitoring and assessment framework and has adopted it as a baseline indicator in various projects at the country level. The SCI is based on publicly available data, and this has various advantages over other indexes of statistical capacity. A key advantage of the SCI is that it can provide assessment of a country’s statistical capacity in an internationally comparable and cost-effective manner.

Yet, there are several areas in which the existing SCI can be improved. First, it comprises of a limited number of indicators and includes no indicators of some important data sources, such as labor force surveys, establishment surveys, or administrative data. Second, it ignores the data dissemination practices of an NSS, which is one of the key features of data usage. Third, the SCI has been criticized for placing too much weight on statistical output and activities, while neglecting the infrastructure and resource components of statistical systems.  Finally, it is silent on whether the data products produced by the NSS are in high demand. 

Since its launch in 2004, the SCI’s methodology and coverage have basically remained the same, while the global data landscape has changed significantly. NSSs have made significant advancements with data collection and dissemination practices. At the same time, the adoption of the Sustainable Development Goals (SDGs) set an ambitious development agenda for the next 15 years on ending poverty, protecting the planet, and ensuring prosperity for all by 2030. This, in turn, increased the demand for data and raised the bar for national statistical systems regarding their capacity to produce high-quality data. We thus propose to improve the current SCI to better suit the changing global data landscape.

# Overview of the New SPI

The new Statistical Performance Indicators (SPI) builds on the SCI, which the World Bank has regularly published since 2004.  Our new SPI will cover many of the same elements as the SCI, such as statistical methodology, source data, and periodicity, but will also expand into new areas. The goals are to offer a framework that was forward looking, measured less mature statistical systems as well as advanced systems, covered the entire national statistical system, not just the National Statistical Office (NSO), and gives countries incentives to build a modern statistical system.  We also are committing to making our project open data and open code to build confidence in our work.

The new Statistical Performance Indicators (SPI) are designed to monitor how well countries statistical systems are meeting this purpose.  By helping countries and development partners identify the strengths and weaknesses of national statistical systems the SPI can support policy advice for countries about their national statistical systems, investment decisions for donors including the World Bank, benchmarking of national statistical systems, and advocacy for national statistics.  

We identify five key dimensions of a country’s statistical performance. These are data use, data services, data products, data sources, and data infrastructure . These dimensions can be presented in the form of a dashboard that can help countries identify areas for development in their statistical system. Improvements in performance can be represented as a virtuous data cycle that can become self-sustaining.

![](SPI_cycle.png)

Statistics have no value unless they are used. The first dimension of the SPI is therefore data use. A successful statistical system is one that produces data products that are highly used. 

In order to meet user needs, the statistical system must develop a range of services that connect data users and producers and facilitate dialogue between them. The second dimension of the SPI is therefore data services that are trusted by users. A successful statistical system is one with highly valued and well used statistical services.

The dialogue between users and suppliers in turn drives the design of statistical products that are to be created including the quality of product needed for the country requirement. This will incorporate accuracy, timeliness, frequency, comparability and levels of disaggregation. The third dimension of the SPI is therefore data products. A successful statistical system is one that generates high quality statistical indicators that can also track progress for the Sustainable Development Goals (SDGs).

In order to create the products required, the statistical system needs to make use of a variety of sources from both inside and outside the government. This will include making use of typical data collection methods like censuses and surveys, but also administrative data, geospatial data, and data generated from the private sector and from citizens.  The fourth dimension of the SPI is therefore data sources.  A successful statistical system is one which draws on all types of data sources relevant to the indicators that are to be produced.

For the cycle to be complete, capability needs continuously to be reviewed to ensure that it is enough to deliver the products, services and ultimately data use required. The fifth dimension of the SPI is therefore data infrastructure. A successful statistical system is one that develops both hard infrastructure (legislation, governance, standards) and soft infrastructure (skills, partnerships) and has the financial resources to deliver.
The 5 dimensions and associated 22 pillars of the SPI are as shown in Figure 1 below.

*Figure 1: The Dimensions and Pillars that Construct the New SPI*
![](SPI_dashboard.png)

A score against each element would facilitate:    

  1. Understanding of the maturity of the national statistical system in relation to others eg quintile groups of countries could be shown against each dimension    
  
  2. This in turn would highlight relative strengths and weaknesses of the system and give an indication of the extent to which the official statistics could be relied upon  
  
  3. It would also point to which other countries the country in question could learn from as it seeks to improve and create incentives to develop in a forward looking rather than backward looking way   
  
  4. Time series would allow assessments to be made of progress of the system and a start point for assessments of return on investment for funding given for capacity building 
  
  5. A dynamic view encouraging continuous improvement. As countries improve the bar for what good looks like would get higher     


Key characteristics of the SPI are: (i) uses only publicly accessible data; (ii) transparent methodology; (iii) easily replicable; (iv) provides a long-time series to track progress in performance; (v) captures outcomes and supporting elements; (vi) reflects the SDGs; (vii) facilitates at-a-glance comparisons on a global scale.
We are collecting data on indicators for the 22 pillars above. For dissemination, the SPI will be presented both in the dashboard format above and as an index for each country. Further details on the construction of the new SPI are provided in the remainder of the document.




```{r data, include=FALSE}

#add in population
pop_df <- wbstats::wb(country="all",
             indicator='SP.POP.TOTL',
             startdate=2004,
             enddate=2019) %>%
  mutate(date=as.numeric(date)) %>%
  mutate(population=value) %>%
  select(country, date, population) 


#read in the SPI dataset
spi_df_final <- read_csv( file = paste(output_dir, 'SPI_data.csv', sep="/")) %>%
  left_join(pop_df) %>%
  mutate(weights=wgt)  #create a variable for weights for estimates.  This just makes is easier to switch between weights and unweighted estimates.



metadata <- read_csv(paste(raw_dir, '/metadata/SPI_dimensions_sources.csv', sep=""))

metadata_full <- read_csv(paste(raw_dir, '/metadata/SPI_index_sources.csv', sep="")) %>%
  rename(source_name=descript) %>%
  bind_rows(metadata)
                             

pillars <- read_csv(paste(raw_dir, '/metadata/SPI_pillars.csv', sep=""))

```



```{r programs, include=FALSE}


#Now map the result
quality = "high"
maps <- wbgmaps::wbgmaps[[quality]]

country_metadata <- wbstats::wbcountries()




spi_mapper  <- function(data, indicator, title) {
  
 indicator<-indicator

  map_df <- get(data) %>%
    filter(date==max(date, na.rm=T)) %>%
    filter(!(country %in% c('Greenland'))) %>% #drop a few countries for which we do not collect data.
    group_by( country) %>%
    #summarise(across(!! indicator,last)) %>%
    rename(data_available=!! indicator) %>%
    select(iso3c, date, data_available, weights) %>%
    right_join(country_metadata) %>%
    mutate(data_available=if_else(is.na(data_available), as.numeric(NA), as.numeric(data_available)))     


  spi_groups_quantiles <- quantile(map_df$data_available, probs=c(1,2,3,4)/5,na.rm=T)
  
  SPI_map <- map_df %>%
    mutate(spi_groups=case_when(
      between(data_available, spi_groups_quantiles[4],100) ~ "Top 20%",
      between(data_available, spi_groups_quantiles[3],spi_groups_quantiles[4]) ~ "4th Quintile",
      between(data_available, spi_groups_quantiles[2],spi_groups_quantiles[3]) ~ "3rd Quintile",
      between(data_available, spi_groups_quantiles[1],spi_groups_quantiles[2]) ~ "2nd Quintile",
      between(data_available, 0,spi_groups_quantiles[1]) ~ "Bottom 20%"
      
    )) %>%
    mutate(spi_groups=factor(spi_groups, 
                             levels=c("Top 20%","4th Quintile","3rd Quintile","2nd Quintile","Bottom 20%" )))  
  
  #set color pallete
  col_pal <- c("#2ec4b6","#acece7","#f1dc76","#ffbf69","#ff9f1c")  
  names(col_pal) <- c("Top 20%","4th Quintile","3rd Quintile","2nd Quintile","Bottom 20%" )
  
  p1<-ggplot() +
    geom_map(data = SPI_map, aes(map_id = iso3c, fill = spi_groups), map = maps$countries) + 
    geom_polygon(data = maps$disputed, aes(long, lat, group = group, map_id = id), fill = "grey80") + 
    geom_polygon(data = maps$lakes, aes(long, lat, group = group), fill = "white")  +
    geom_path(data = maps$boundaries,
              aes(long, lat, group = group),
              color = "white",
              size = 0.1,
              lineend = maps$boundaries$lineend,
              linetype = maps$boundaries$linetype) +
    scale_x_continuous(expand = c(0, 0), limits = standard_crop_wintri()$xlim) +
    scale_y_continuous(expand = c(0, 0), limits = standard_crop_wintri()$ylim) +
    scale_fill_manual(
      name='SPI Score',
      values=col_pal,
      na.value='grey'
    ) +
    coord_equal() +
    theme_map(base_size=12) +
    labs(
      title=str_wrap(title,100),
      caption = 'Source: World Bank. Statistical Performance Indicators'
    )
 print(p1)
}

spi_charts  <- function(data, indicator, title) {
  
    map_df <- get(data) %>%
    filter(date==max(date, na.rm=T)) %>%
    filter(!(country %in% c('Greenland'))) %>% #drop a few countries for which we do not collect data.
    group_by( country) %>%
    #summarise(across(!! indicator,last)) %>%
    rename(data_available=!! indicator) %>%
    select(iso3c, date, data_available, weights) %>%
    right_join(country_metadata) %>%
    mutate(data_available=if_else(is.na(data_available), as.numeric(NA), as.numeric(data_available)))  
    
    
    
    
  #add histogram by region 
  p2 <- map_df %>%
    group_by(region) %>%
    filter(region!='Aggregates') %>%
    mutate(Percentage=wtd.mean(data_available, weights = weights, na.rm=T),
           Label = paste(round(Percentage,0))) %>%
    ggplot(aes(x=Percentage, y=region, fill=region)) +
      geom_bar(stat="identity",position='dodge') +
      geom_text(aes(label=Label)) +
      labs(
      title=str_wrap(paste(title, 'By Region', sep=" - "),100),
      caption = 'Source: SPI Indicators Raw Data',
      subtitle= 'Data Point is for last year available (2019)'
      ) +
      expand_limits(x=c(0,100)) +
      theme_bw() +
      theme(legend.position = 'top')


  # p2_alt <- map_df %>%
  #   ungroup() %>%
  #   filter(region!='Aggregates') %>%
  #   mutate(Percentage=(data_available),
  #          Label = paste(round(Percentage,0))) %>%
  #   ggplot(aes(x=Percentage, y=region, color=region)) +
  #     geom_point() +
  #     geom_text(aes(label=country), position=position_jitter(width=.1,height=.4), check_overlap=T) +
  #     labs(
  #     title=str_wrap(paste(title, 'By Country', sep=" - "),100),
  #     caption = 'Source: SPI Indicators Raw Data',
  #     subtitle= 'Data Point is for last year available (2019)'
  #     ) +
  #     expand_limits(x=c(0,100)) +
  #     theme_bw() +
  #     theme(legend.position = 'top')  
  
  #by income
    income <- c("Low income", "Lower middle income","Upper middle income","High income")

    p3 <- map_df %>%
    group_by(income) %>%
    filter(region!='Aggregates') %>%
    mutate(Percentage=wtd.mean(data_available, weights = weights, na.rm=T),
           Label = paste(round(Percentage,0))) %>%
    ggplot(aes(x=Percentage, y=income, fill=income)) +
      geom_bar(stat="identity",position='dodge') +
      geom_text(aes(label=Label)) +
      labs(
      title=str_wrap(paste(title, 'By Income', sep=" - "),100),
      caption = 'Source: SPI Indicators Raw Data',
      subtitle= 'Data Point is for last year available (2019)'
      ) +
      scale_y_discrete(limits = income) +
      expand_limits(x=c(0,100)) +
      theme_bw() +
      theme(legend.position = 'top')
    
  # #add line graph over time
  p4 <- get(data)  %>%
    rename(data_available=!! indicator) %>%
    # right_join(spi_df_empty) %>%
    group_by(income, date) %>%
    mutate(data_available=if_else(is.na(data_available), as.numeric(NA), as.numeric(data_available))) %>%
    mutate(Percentage=wtd.mean(data_available, weights = weights, na.rm=T),
           Label = paste(round(Percentage,0))) %>%
    ungroup() %>%
    ggplot(aes(y=Percentage, x=date, color=income)) +
      geom_point() +
      geom_line() +
      # geom_text_repel(aes(label=Label)) +
      labs(
      title=str_wrap(paste(title, 'By Date', sep=" - "),100),
      caption = 'Source: SPI Indicators Raw Data'
      ) +
      expand_limits(y=c(0,100)) +
      theme_bw() +
      theme(legend.position = 'top')
  

            
      

  print(p2)
  

  print(p3)

  print(p4)
    
}

spi_country_charts  <- function(data, indicator, title) {
  

 indicator<-indicator

  map_df <- get(data) %>%
    filter(date==max(date, na.rm=T)) %>%
    filter(!(country %in% c('Greenland'))) %>% #drop a few countries for which we do not collect data.
    group_by( country) %>%
    #summarise(across(!! indicator,last)) %>%
    rename(data_available=!! indicator) %>%
    select(country, date, data_available, weights ) %>%
    right_join(country_metadata) %>%
    filter(region!="Aggregates") %>%
    mutate(data_available=if_else(is.na(data_available), as.numeric(NA), as.numeric(data_available)))    
  
   spi_groups_quantiles <- quantile(map_df$data_available, probs=c(1,2,3,4)/5,na.rm=T)
  
  SPI_map <- map_df %>%
    mutate(spi_groups=case_when(
      between(data_available, spi_groups_quantiles[4],100) ~ "Top 20%",
      between(data_available, spi_groups_quantiles[3],spi_groups_quantiles[4]) ~ "4th Quintile",
      between(data_available, spi_groups_quantiles[2],spi_groups_quantiles[3]) ~ "3rd Quintile",
      between(data_available, spi_groups_quantiles[1],spi_groups_quantiles[2]) ~ "2nd Quintile",
      between(data_available, 0,spi_groups_quantiles[1]) ~ "Bottom 20%"
      
    )) %>%
    mutate(spi_groups=factor(spi_groups, 
                             levels=c("Top 20%","4th Quintile","3rd Quintile","2nd Quintile","Bottom 20%" )))  
  
  #set color pallete
  col_pal <- c("#2ec4b6","#acece7","#f1dc76","#ffbf69","#ff9f1c")  
  names(col_pal) <- c("Top 20%","4th Quintile","3rd Quintile","2nd Quintile","Bottom 20%" )
  

  p2_alt <- SPI_map %>%
    ungroup() %>%
    ggplot(aes(x=data_available, y=region, color=spi_groups)) +
      geom_point() +
      geom_text(aes(label=country), position=position_jitter(width=.1,height=.4), check_overlap=T) +
      labs(
      title=str_wrap(paste(title, 'By Country', sep=" - "),100),
      caption = 'Source: SPI Indicators Raw Data',
      subtitle= 'Data Point is for last year available (2019)'
      ) +
      xlab('Score') +
      expand_limits(x=c(0,100)) +
      scale_color_manual(
        name='SPI Score',
        values=col_pal,
        na.value='grey'
      ) +
      theme_bw() +
      theme(legend.position = 'top') 
   
p2_alt

}


spi_maturity_table <- function(data, indicators, reference_year) {

      df_overall <- get(data) %>%
      filter(date==as.numeric(reference_year)) %>% 
      select(country, iso3c, date, income, region, all_of(indicators), SPI.INDEX) 
    
    
    spi_groups_quantiles <- quantile(df_overall$SPI.INDEX, probs=c(1,2,3,4)/5,na.rm=T)
    
    df_overall <- df_overall %>%
      mutate(spi_groups=case_when(
        between(SPI.INDEX, spi_groups_quantiles[4],100) ~ "Top 20%",
        between(SPI.INDEX, spi_groups_quantiles[3],spi_groups_quantiles[4]) ~ "4th Quintile",
        between(SPI.INDEX, spi_groups_quantiles[2],spi_groups_quantiles[3]) ~ "3rd Quintile",
        between(SPI.INDEX, spi_groups_quantiles[1],spi_groups_quantiles[2]) ~ "2nd Quintile",
        between(SPI.INDEX, 0,spi_groups_quantiles[1]) ~ "Bottom 20%"
      )) %>%
      mutate(spi_groups=factor(spi_groups, 
                               levels=c("Top 20%","4th Quintile","3rd Quintile","2nd Quintile","Bottom 20%" )))  
    
    #produce by income
    sumstats<- df_overall %>%
      group_by(spi_groups) %>%
      filter(!is.na(spi_groups)) %>%
      select(spi_groups, all_of(indicators)) %>%
      summarise_all(~round(mean(., na.rm=T),1)) 
    
    #produce global number
    sumstats_gl<- df_overall %>%
      mutate(spi_groups='Global') %>%
      group_by(spi_groups) %>%
      select(spi_groups, all_of(indicators)) %>%
      summarise_all(~round(mean(., na.rm=T),1)) 
    
    
    #transpose data
    sumstats_df_long <-sumstats 
    
    sumstats_df <- as.data.frame(t(sumstats_df_long %>% select(-spi_groups)))
    colnames(sumstats_df) = sumstats_df_long$spi_groups 
    
    
    sumstats_df <- sumstats_df %>%
      rownames_to_column() %>%
      rename(series=rowname)
    
    
    #create labels df
    metadata_tab2_overall <- metadata_full %>% 
      janitor::clean_names() %>%
      transmute(series=source_id, 
                indicator_name=source_name)
    
    
    #add variable label
    sumstats_df <- sumstats_df %>%
      left_join(metadata_tab2_overall) %>%
      rename(Series=series,
             Label=indicator_name) %>%
      mutate(Label=if_else(is.na(Label),Series,Label)) %>%
      select(Label, c("Top 20%","4th Quintile","3rd Quintile","2nd Quintile","Bottom 20%" ))

      sumstats_df
 

  }

#define function to pull data from UN Stats and return
un_pull <- function(series,start, end) {
  # jsonlite::fromJSON(paste('https://unstats.un.org/SDGAPI/v1/sdg/Series/Data?seriesCode=',series,'&timePeriodStart=',start,'&timePeriodEnd=',end,'&pageSize=10000',sep=""), flatten = TRUE)$data %>%
      jsonlite::fromJSON(paste('https://unstats.un.org/SDGAPI/v1/sdg/Series/Data?seriesCode=',series,'&pageSize=10000',sep=""), flatten = TRUE)$data %>%

    as_tibble() %>%
    mutate(date=timePeriodStart) %>%
    right_join(iso3c)
    
}  

FitFlextableToPage <- function(ft, pgwidth = 6){

  ft_out <- ft %>% autofit()

  ft_out <- width(ft_out, width = dim(ft_out)$widths*pgwidth /(flextable_dim(ft_out)$widths))
  return(ft_out)
}

```

# Pillars of the new SPI


A quick primer on names. We refer to the 5 rows in the framework in Figure 1 as dimensions. We refer to the 22 cells in the framwork in Figure 1 as pillars. Finally, each pillar may be composed of multiple indicators. For instance, the pillar on censuses and surveys is made up indicators on whether population censuses have been conducted, agriculture censuses, labor force surveys, etc.

## Data use

The data use dimension is segmented by user type. The tiles on the Dashboard provide an indicator of use of statistics respectively by the legislature, executive, civil society (including sub-national actors), academia and international bodies. A mature system would score well across the tiles. Areas for development would be highlighted by weaker scores in that domain enabling questions to be asked about prioritization amongst user groups and why existing services are not resulting in higher use of national statistics in that segment.

## Data services

The data services dimension is segmented by service type. The tiles on the Dashboard provide an indicator of the quality of data releases, the richness and openness of online access, the effectiveness of advisory and analytical services related to statistics and the availability and use of data services such as secure microdata access. Advisory and analytical services might incorporate elements related to data stewardship services including ethical consideration of proposals and calling out misuse of data in accordance with the Fundamental Principles of Official Statistics.

## Data products

The data products dimension is segmented by topic and organized into social, economic, environmental and institutional domains using the typology of the Sustainable Development Goals. This approach enables comparisons across countries and anchors the system in the 2030 agenda so that a global view can be generated whilst enabling different emphasis to be applied in different countries to reflect the user needs of that country.

## Data sources

The data sources dimension is segmented between sources generated by the statistical office (censuses and surveys) and sources accessed from elsewhere (administrative data, geospatial data, private sector data and citizen generated data). The appropriate balance between these types of source will vary depending on the institutional setting and maturity of the statistical system in each country. High scores should reflect the extent to which the sources being utilized enable the necessary statistical indicators to be generated. For example, a low score on environment statistics may reflect a lack of use of (and low score for) geospatial data. This linkage, which is inherent in the data cycle approach, should help highlight areas for investment if country needs are to be met.

## Data infrastructure

The data infrastructure dimension is segmented into hard and soft infrastructure segments itemizing essential cross cutting requirements for an effective statistical system. The segments are:   

  1. Legislation and governance covering the existence of laws and a functioning institutional framework for the statistical system    
  
  2. Standards and methods addressing compliance with recognized frameworks and concepts   
  
  3. Skills including level of skills within the statistical system and amongst users (statistical literacy)   
  
  4. Partnerships reflecting the need for the statistical system to be inclusive and coherent    
  
  5. Finance, both domestically and from donors    
  
## Indicators and weights    

We are seeking answers to the questions:    

  1. What indicator (that we can measure in practice) could act as a proxy measure for the concept we are trying to capture?   
  
  2. What weight can we assign to the indicator that allows this concept to be aggregated with others in a meaningful way?   
  
  There will be no right answer to these questions and the proposed approach makes a virtue of this by: 
  
  1. Allowing missing values and setting out how missing values are dealt with for the purposes of making comparisons over time and between countries    
  
  2. Providing users the opportunity to apply their own weights    
  
  3. Releasing the dashboard as a “Beta” and encouraging a research agenda to help fill in gaps and improve any elements   
  
  4. Establishing a process for review that enables time series to be respected.   
  
  5. Presenting the dashboard within a toolkit for understanding statistical performance   



Below is a brief description of the 22 pillars in our framework.  A detailed description of the underlying indicators populating the pillars is also available in the annex.



```{r metadatatab1}
####
# create table
####

pillars <- pillars %>%
  mutate(pillar=paste(pillar_number, pillar_name, sep=": ")) %>%
  select(pillar, spi_indicator_description)


pillars_tab <- flextable(pillars) %>%
  add_header_lines('SPI Pillars Metadata.') %>%
  set_header_labels(values=list(
                       pillar="Pillar",
                       spi_indicator_description="Brief Description"
                                   )) 

FitFlextableToPage(pillars_tab) %>%
  width(width=3.2) %>%
  align( align = "left", part = "body")


```

# SPI Data

Thanks to a large scale data collection effort by several organizations including the World Bank, IMF, Open Data Watch, PARIS21, the ILO, WHO, UNESCO, IHSN, and the UN, among others, we were able to compile 54 indicators covering 14 out of our 22 pillars for our dashboard.  These 54 indicators do allow us to provide data for each of our 5 dimensions on data use, data services, data products, data sources, and data infrastructure.  Yet, there remain major gaps in what we are able to measure, and the gaps may mean we are flying blind in some areas on whether statistical systems are meeting the needs of the public.  Going forward, the international community must work together to fill these gaps.

An area of particular concern is in the dimension of data use.  Currently, our dashboard only features data for one of the five pillars in data use.  That is on data use by international organizations.  We are currently blind as to whether statistical systems are providing useful data to their national governments (legislature and executive branches), to civil society, and to academia.  By closing this data gap, country national statistical offices (NSOs) can be better guided in whether the information they are providing is meeting their user's needs.  International organizations can help steer funding for capacity building in areas that are lacking.  And the virtuous data cycle can begin: where better investment leads to more effectiveness, then more innovation, higher value-added, and ultimately greater impact.

Another area that needs improvement is in the measurement of advisory and analytical services provided by NSOs, such as data stewardship services and the ethical consideration of proposals.  By measuring this type of work done by NSOs that goes beyond producing data, the international community and the NSOs themselves can better assess whether this type of support is in place.

In the area of data sources, more information is needed particularly in the areas of administrative data, geospatial data, and private and citizen generated data.  While we have measures of administrative data use, particularly on the development of civil registrations and vital statistics systems, we have an incomplete picture of whether the administrative data systems are in place to measure health, education, labor, and social protection program statistics.  For our geospatial indicator, we have a proxy measure of whether the country is able to produce indicators at the sub-national level, but we lack an understanding of how countries are using geospatial information in other ways, for instance using satellite data.  And while the world is increasingly awash with private and citizen generated data, such as on mobility, job searching, or social networking, we were unable to find a reliable source to measure how national statistical systems are incorporating this information.

Finally, many of the soft components of data infrastructure lacked adequate data.  This includes the areas of skill (including data literacy) and partnerships between entities in the national statistical system.  We are making use of the PARIS21 led SDG indicator on whether statistical legislation met the standards of the UN fundamental Principles of Statistics in our dashboard, but were unable to use this in our index, because countries have not sufficiently reported to PARIS21 on this measure.  This is also true of the PARIS21 led SDG indicator on whether the national statistical system is fully funded.  Countries should be encouraged to report on this information.

Below is a brief description of the information (or lack thereof) we have available for the pillars in our framework.  For pillars excluded, we either lacked a source with a developed methodology or else the data collection for that measure was incomplete. This is described below:

  * **Pillar 1.1: Data use by national legislature:**  *Not included because of lack of established methodology.  In principle it may be possible to utilize websites of national legislatures but this will require further work and assessment. *   
  * **Pillar 1.2: Data use by national executive branch:** *Not included because of lack of established methodology. There are some usable data sources with fairly good coverage (as used by PARIS21) but gaps in data have prevented fuller assessment of suitable methods.*      
  * **Pillar 1.3: Data use by civil society:**  *Not included because of lack of established methodology. There are some usable data sources with good coverage, for example from social media but more data is required to help assess and allow for likely biases between and within countries.*    
  * **Pillar 1.4: Data use by academia:**  *Not included because of lack of established methodology. We have not been able to find usable data sources with global coverage on which a new methodology could be developed.*   
  * **Pillar 1.5: Data use by international organizations:**  *Reliability/Usefulness of Poverty, Child Mortality, Debt Statistics, safely managed drinking water, and labor force statistics data for international agencies using metadata. We recognize that these data sources provide only partial coverage but consider that they do at least provide some indication of the performance of the national statistical system. With more complete data sources it would be possible to assess this further*    

  
  * **Pillar 2.1: Data Releases:** *SPI.D2.1.GDDS -	SDDS/e-GDDS subscription. This is a good data source but we recognize that it is a proxy for the concept we are seeking to capture rather than a direct measurement.*    
  * **Pillar 2.2: Online access:** *SPI.D2.2.Openness.subscore	ODIN Open Data Openness score.  This is a well-established data source with good country coverage. In using this indicator, it is important to describe carefully what is captured since the purpose of ODIN is different to the purpose of the SPI.*   
  * **Pillar 2.3: Advisory/ Analytical Services:**  *Not included because of lack of established methodology. We recognize that this data source provides only limited coverage but consider that it does at least provide some indication of the performance of the national statistical system. With more complete data sources it would be possible to assess this further.*    
  * **Pillar 2.4: Data services:** *SPI.D2.4.NADA	NADA metadata.  We have not been able to find usable data sources with global coverage on which a new methodology could be developed.*
  
  * **Pillar 3.1: Social Statistics:** *Average score for Goal 1-6 indicators. The primary data source is the UN SDG database. Whilst this is a database with comprehensive coverage that all countries have signed up to, it is clear that many (particularly developed countries) are not yet submitting their available national data. Scores for these countries are likely to represent an indicator of their willingness to submit national data rather than their performance in calculating the indicators.  For OECD countries, we supplement the UN SDG database with comparable data submitted to the OECD following the methodology in Measuring Distance to the SDG Targets 2019: An Assessment of Where OECD Countries Stand (https://www.oecd.org/sdd/measuring-distance-to-the-sdg-targets-2019-a8caf3fa-en.htm). *
  * **Pillar 3.2: Economic Statistics:** *Average score for Goal 7-12 indicators. See 3.1.*  
  * **Pillar 3.3: Environmental Statistics:**  *Average score for Goal 13-15 indicators. See 3.1.*      
  * **Pillar 3.4: Institutional Statistics:** *Average score for Goal 16-17 indicators. See 3.1.*    

  * **Pillar 4.1: Censuses and Surveys:** *Average score Census and Survey Indicators indicators.  In this release of the SPI the data and methods used for this indicator are the same as for the previous SPI. Further work could improve the validity of this indicator and reduce the risk that countries may be incentivized to adopt outdated practices for censuses and surveys.*
  * **Pillar 4.2: Administrative Data:** *Average score for CRVS indicator.  Social Protection, Education, and Labor admin data indicators not included because of lack of established methodology. While our team identified several promising sources for administrative data from the World Bank's ASPIRE team, UNESCO, and ILO, incomplete coverage across countries made us drop these indicators from our index.  A major research and data collection effort is needed from all custodian agencies  to fill in this information, so that a more comprehensive picture of administrative data availability can be produced.  *  
  * **Pillar 4.3: Geospatial Data:**  *SPI.D4.3.GEO.first.admin.level -	Geospatial data available at 1st Admin Level.  We recognize that this data source provides only limited coverage but consider that it does at least provide some indication of the ability of the national statistical system to produce geospatial data. A major research and data collection effort is needed via GGIM to fill in this information, so that a more comprehensive picture of geospatial data capability at the national level can be produced. Until this is done, it we cannot even assess the scale of the data gaps in a comparable way. * 
  * **Pillar 4.4: Private/citizen generated data:**  *Not included because of lack of established methodology.  Currently no comprehensive source exists to measure the use of private and citizen generated data in national statistical systems, and this should be another area where more data collection is needed by the international community.*   
  
  * **Pillar 5.1: Legislation and governance:**  *Included in dashboard, but not index because of insufficient country coverage.  A global database of statistical and data legislation and governance practice would be a valuable resource for capacity building in general not just for the SPI.*  
  * **Pillar 5.2: Standards and Methods:** *Average score for Standards and Methods indicators.  In this release of the SPI the data and methods used for this indicator are the same as for the previous SPI. Further work could improve the validity of this indicator and reduce the risk that countries may be incentivized to adopt only traditional standards and methods and neglect innovative solutions that may be more valid in the current context.  *  
  * **Pillar 5.3: Skills:**  *Not included because of lack of established methodology or suitable data sources*    
  * **Pillar 5.4: Partnerships:**  *Not included because of lack of established methodology or suitable data sources*    
  * **Pillar 5.5: Finance:**  *Included in dashboard, but not index because of insufficient country coverage and concerns that the indicator has biases that would lead to misleading incentives. * 
  

This process of eliminating some pillars due to lack of established methodology or country coverage results in 12 pillars. This includes 1 on data use, 3 on data services, 4 on data products, 3 on data sources, and 1 on data infrastructure.

# SPI Index Methodology 

We next produce an overall score by combining the indicators we have collected.  Our statistical performance indicators have a three level structure, and our SPI overall score will be formed by sequentially aggregating each level.

To begin we produce a score for each pillar, which is an unweighted average of the indicators within that pillar.  For instance, the Census and Surveys pillar will be formed by taking the unweighted average of the Population Census score, the Agriculture Census score, the Business Census score, the Labor Force Survey score, the Health Survey score, etc.  

$$ SPI.PILLAR_{ctds} = \sum_{i=1}^{N_I} \frac{SPI.IND_{ctdsi}}{N_I} $$

where $SPI.PILLAR_{ctds}$ is pillar s, in dimension d, in time period t, and country c.  $SPI.IND_{ctdsi}$ is an indicator (e.g. population census score).

After computing a score for the pillar, we then compute a dimension score, which is the average of the pillars in that dimension. For dimensions 1, 2, 4, and 5, we take the unweighted average of the pillars in the dimension.  However, for Dimension 3 on data products, we take a weighted average of the pillars, where the weights are based on the number of SDGs in each pillar (6 SDGs in Pillar 3.1 on social statistics, 6 SDGs in Pillar 3.2 on economic statistics, 2 in Pillar 3.3 on environmental statistics, and 2 in Pillar 3.4 on institutional statistics).  We take the perspective that all SDGs are of equal importance, and therefore weight our pillars accordingly.

$$ SPI.DIM_{ctd} = \sum_{s=1}^{N_S} \frac{\omega_{ds} \times SPI.PILLAR_{ctds}}{N_S} $$

$\omega_{ds}$ is the weight for pillar s in dimension d.

After calculating the scores for each dimension, the SPI overall score is the average across the 5 dimensions. 

The SPI overall score is scaled to have a maximum score of 100 and a minimum of 0. A score of 100 would indicate that a country has every single element that we measure in place. A score of 0 indicates that none are in place. To be precise:



$$ SPI.INDEX_{ct} = \sum_{d=1}^{N_D} \frac{SPI.DIM_{ctd}}{N_D} $$

Where SPI.INDEX is the SPI overall score. SPI.DIM are the 5 SPI dimensions listed above. In the notation, c is a country, t is the date, d is a dimension.  

The nested structure of our index and the summation methods used to build an overall score ensure the axiomatic properties outlined in [@cameron2019measuring].  These include symmetry, monotonicity, and subgroup decomposability.

## Handling Missing Data 

For a full description of the methodology behind each specific indicator, please consult the technical documentation.  However, we did follow an approach of handling missing values and lining up data, which will be describe in general terms below.  For indicators where we had a value for a previous year (say a value in 2018 but not 2019), we would fill in from the previous value.  For instance, the open data watch indicators on geo-spatial data was only released in 2018, not 2019, so we filled in the value for 2019 with the value from 2018 as our best estimate of that indicator.

For indicators where we had no data for any years, we chose not to impute a value.  In that case, the value for that indicator is null and the country will not have a value for any pillars or dimensions where that value is used.


## Process for Disputing the Data

Countries will be given an opportunity to dispute the values that make up our indicators.  Our team takes every effort to make sure the data presented in ouf Statistical Performance Indicators are accurate, but it is possible that the sources we used to assign values for our indicators are not accurate despite these efforts.  Because of this, countries will have a window to provide documentation for any disputed values, and our team will be happy to adjust our scores based on this new information.  Precise details for this process will be made available in the future.

## Process for Updating Indicators

While we feel our framework is comprehensive and is designed to capture the contours most statistical systems over at least the next 15 years, we fully recognize that our indicators themselves have room for improvement.  At launch, we will tag our version of our statistical performance indicators as version 1.0.  From there, we will likely have a 2-3 year cycle, where we continuously update the values of our indicators, but do not change the methodology for constructing them. At the end of the 2-3 year period, we may introduce a indicator or we may re-evaluate how our current indicators are constructed based on feedback from countries and other groups.  At that point, we will launch a major update as version 2.0, or version 3.0 as the sequence goes.  Smaller updates, where for instance we adjust a countries value based on the data dispute process we describe above, will be labeled with a decimal point as version 1.1 for instance.

In order to be completely transparent, we will track all changes to our methodology through a publicly available github repository and we will publish all code and underlying data to produce our indicators.

# SPI Overall Scores


```{r spi_df}

# This block of code will create a blank SPI dataset (only containing country info) that will be appended to when each indicator is added.
# There will be two indicators added for each dimension
# 1. An indicator with a score between 0-1 for each dimension
# 2. An indicator with the raw (unscored) values of the indicators
# The unit for this database will be country*year

span <- c(2004:2019)

spi_df_empty <- bind_rows(replicate(length(span), wbstats::wbcountries(), simplify = FALSE), .id='date') %>%
  mutate(date=as.numeric(date)+span[1]-1) %>%
  filter(region!="Aggregates") # take out the aggregates (LAC, SAR, etc)

spi_df <- spi_df_empty

#read list of iso3c codes for matching from UN (https://unstats.un.org/unsd/methodology/m49/)
iso3c <- read_csv(paste(raw_dir,'metadata/iso_codes.csv', sep="/"),
                  col_types=list(col_character(), col_character(), col_character()))

```
  

```{r index}
#get a list of oecd countries
oecd_country_query <-  GET(url = "https://api.worldbank.org/v2/country?region=OED&format=json") %>%
  content( as = "text", encoding = "UTF-8") %>%
  jsonlite::fromJSON( flatten = TRUE) 

#do some conversion to produce a dataframe
oecd_country_df <- oecd_country_query[[2]] %>%
  as_tibble() 
  
country_mod_list <- oecd_country_df$name  #fill in the missing values for OECDs with 1s because by participating in OECD these countries have this
country_mod_list <- c(country_mod_list, 'Singapore')
# create index dataset
spi_index_df_temp <- spi_df_final %>%
  select(country, iso3c, date, starts_with("SPI"), income, region, weights, population) %>%
  arrange(-date,country)

#Drop certain indicators that don't make cut because of imcomplete coverage usually
spi_index_df_temp <- spi_index_df_temp %>%
  select( -SPI.D5.3.DISK, -SPI.D4.3.GEO.second.admin.level) 





#first index 
# just take a simple numeric average acorss all indicators
# I will forward fill all indicators if they are missing
spi_index_simple <- spi_index_df_temp %>%
  arrange(country, date) %>%
  group_by(country) %>%
  select(-starts_with("SPI.D1")) %>%
  mutate(across(starts_with("SPI"), na.locf, na.rm=FALSE)) %>%
  mutate(SPI.INDEX=rowMeans(across(starts_with("SPI")), na.rm=FALSE),
         SPI.INDEX.DIM2=rowMeans(across(starts_with("SPI.D2")), na.rm=FALSE),
         SPI.INDEX.DIM3=rowMeans(across(starts_with("SPI.D3")), na.rm=FALSE),
         SPI.INDEX.DIM4=rowMeans(across(starts_with("SPI.D4")), na.rm=FALSE),
         SPI.INDEX.DIM5=rowMeans(across(starts_with("SPI.D5")), na.rm=FALSE)
         ) %>% #
  arrange(-date, -SPI.INDEX) %>%
  select(country, iso3c, date, starts_with('SPI.INDEX'), everything())


#################
# Nested Index
################
  spi_index_df <- spi_index_df_temp %>%
  arrange(country, date) %>%
  group_by(country) %>%
  mutate(across(starts_with("SPI"), na.locf, na.rm=FALSE)) %>%
  select(country, iso3c, date, everything())



#Create overall subscores corresponding to John's framework
  spi_index_df <- spi_index_df %>%
    mutate(INDEX.SPI.D2.1=rowMeans(across(starts_with('SPI.D2.1'))),
         INDEX.SPI.D2.2=SPI.D2.2.Openness.subscore,
         INDEX.SPI.D2.4=SPI.D2.4.NADA,
         INDEX.SPI.D3.1=rowMeans(across(c("SPI.D3.1.POV",
                                            "SPI.D3.2.HNGR",
                                            "SPI.D3.3.HLTH",
                                            "SPI.D3.4.EDUC",
                                            "SPI.D3.5.GEND",
                                            "SPI.D3.6.WTRS"))),
         INDEX.SPI.D3.2=rowMeans(across(c("SPI.D3.7.ENRG",
                                            "SPI.D3.8.WORK",
                                            "SPI.D3.9.INDY",
                                            "SPI.D3.10.NEQL",
                                            "SPI.D3.11.CITY",
                                            "SPI.D3.12.CNSP"))),         
         INDEX.SPI.D3.3=rowMeans(across(c("SPI.D3.13.CLMT",
                                            "SPI.D3.15.LAND" ))),
         INDEX.SPI.D3.4=rowMeans(across(c("SPI.D3.16.INST",
                                            "SPI.D3.17.PTNS" ))),
         INDEX.SPI.D4.1=rowMeans(across(starts_with('SPI.D4.1'))),
         INDEX.SPI.D4.2=rowMeans(across(starts_with('SPI.D4.2'))),
         INDEX.SPI.D4.3=rowMeans(across(starts_with('SPI.D4.3'))),
         #INDEX.SPI.D5.1=rowMeans(across(starts_with('SPI.D5.1'))),
         INDEX.SPI.D5.2=rowMeans(across(starts_with('SPI.D5.2'))),
         #INDEX.SPI.D5.5=rowMeans(across(starts_with('SPI.D5.5')))
                 ) %>%
  mutate(
         SPI.INDEX.DIM1=rowMeans(across(starts_with("SPI.D1.5")), na.rm=FALSE),
         SPI.INDEX.DIM2=rowMeans(across(starts_with("INDEX.SPI.D2")), na.rm=FALSE),
         SPI.INDEX.DIM3=(6*INDEX.SPI.D3.1 + 6*INDEX.SPI.D3.2 + 2*INDEX.SPI.D3.3 + 2*INDEX.SPI.D3.4)/16,
         SPI.INDEX.DIM4=rowMeans(across(starts_with("INDEX.SPI.D4")), na.rm=FALSE),
         SPI.INDEX.DIM5=rowMeans(across(starts_with("INDEX.SPI.D5")), na.rm=FALSE),
         SPI.INDEX=rowMeans(across(c('SPI.INDEX.DIM1',
                                     'SPI.INDEX.DIM2',
                                     'SPI.INDEX.DIM3',
                                     'SPI.INDEX.DIM4',
                                     'SPI.INDEX.DIM5')), na.rm=FALSE)
         ) %>% #
  mutate(across(starts_with('SPI.INDEX'),~100*.)) %>%
  arrange(-date, -SPI.INDEX) %>%
  select(country, iso3c, date, starts_with('SPI.INDEX'), everything()) 
  #  filter(date>=2016) #2016 is first year with complete data

  
#display top 25
index_disp <- spi_index_df %>%
  ungroup() %>%
  filter(date==2019) %>%
  arrange(-SPI.INDEX) %>%
  mutate(across(starts_with('SPI.INDEX'),~1*.),
         across(starts_with('SPI.INDEX'),round,1)) %>%
  select(country, iso3c, date, starts_with('SPI.INDEX'))


```



```{r saver, include=FALSE}


spi_index_df %>%
  write_excel_csv(path=paste(output_dir, 'SPI_index.csv', sep="/"))

#add stata labels and save a stata version
#read in the data labels
metadata_info <- read_csv(paste(raw_dir, '/metadata/SPI_dimensions_sources.csv', sep="")) %>%
    mutate(descript=paste(SPI_indicator_id,": ", spi_indicator_name," - ",source_name , sep="")) %>%
    select(source_id,  descript, spi_indicator_description)

metadata_info <- read_csv(paste(raw_dir, '/metadata/SPI_index_sources.csv', sep="")) %>%
  bind_rows(metadata_info)

#create a copy of the data to save to stata
spi_index_dta <- spi_index_df

#get a list of the labels and apply them
labels <- metadata_info[match(colnames(spi_index_dta),metadata_info$source_id),2]
labels <- labels$descript
names(labels) <-colnames(spi_index_dta)
  
label(spi_index_dta) <- as.list(labels)

#save stata compatible version with labels
spi_index_dta %>%
  janitor::clean_names() %>%
  haven::write_dta(path=paste(output_dir, 'SPI_index.dta', sep="/"))

#save a copy with column labels as well to csv
l <- lapply(spi_index_dta, attr, "label") # Gives you list of the labeled variables
l <- as.data.frame(l, stringsAsFactors = F) # Convert list to dataframe
spi_index_dta_lab <- rbind(l, spi_index_dta) %>%
  write_excel_csv(path=paste(output_dir, 'SPI_index_labelled.csv', sep="/"),
                  na="") # Bind the two


#for rest of paper, restrict to just 2016, which is where we have complete data
spi_index_df <- spi_index_df %>%
  filter(date>=2016)

```


```{r text_computations}

#number of countries with data for SPI overall score
n_countries <- spi_index_df %>%
  filter(!is.na(SPI.INDEX) & date==2019) %>% #countries with value for SPI in 2019
  nrow()

# percentage of world population covered
pop_covered <- spi_index_df %>%
  filter(date==2019) %>%
  mutate(covered=!is.na(SPI.INDEX)) %>%
  mutate(covered_pop=if_else(covered==TRUE, population, 0)) %>%
  ungroup() %>%
  summarise(pop_covered=sum(covered_pop, na.rm=T)/sum(population, na.rm=T))


```


Below we show a set of summary measures for our SPI overall score.  We begin by presenting a world map containing the SPI overall score values for 2019 for each country.  In total, we have `r n_countries` countries with sufficient data to compute an index value.  This set of countries covers `r 100*round(pop_covered$pop_covered,3)` percent of the world population.

The map is color coded based on the performance of countries on our index.  Given the imprecision inherent in the calculations we recommend that the color coding provides the most detailed subdivisions of maturity. Finer distinctions are unlikely to provide meaningful differentiation between countries. 

Countries shaded in dark red are the lowest performing, countries in dark green are the highest performing.  Countries are grouped into five groups:   

* **Top 20%**:  Countries in the top 20% are classified in this group.  Shading in <span style="color:#2ec4b6">dark green</span>.    
* **4th Quantile**: Countries in the 4th quantile, or those above the 60th percentile but below the 80th percentile are in this group.  Shading in <span style="color:#acece7">light green</span>.    
* **3rd Quantile**: Countries in the 3rd quantile, or those between the 40th and 60th percentile, are classified in this group.  Shading in <span style="color:#f1dc76">yellow</span>.  
* **2nd Quantile**: Countries in the 2nd quantile, or those above the 20th percentile but below the 40th percentile, are in this group.  Shading in <span style="color:#ffbf69">light orange</span>.  
* **Bottom 20%**: Countries in the bottom 20% are classified in this group.  Shading in <span style="color:#ff9f1c">dark orange </span>.    


```{r map}
#show map and summary stats by region and income group

spi_mapper('spi_index_df','SPI.INDEX','SPI Overall Score')

```


```{r maturitytable}

indicators<-c("SPI.INDEX","SPI.D1.5.DT.TDS.DPPF.XP.ZS","SPI.D2.2.Openness.subscore","SPI.D3.1.POV",
             "SPI.D4.1.1.POPU","SPI.D5.2.4.CPIBY")

maturity_tab <- spi_maturity_table('spi_index_df',indicators,2019) 

spi_top <- as.numeric(maturity_tab[1,2])
spi_bottom <- as.numeric(maturity_tab[1,6])

debt_top <- as.numeric(maturity_tab[2,2])
debt_bottom <- as.numeric(maturity_tab[2,6])

census_top <- as.numeric(maturity_tab[5,2])
census_bottom <- as.numeric(maturity_tab[5,6])

```


The maturity model reflects concrete differences between countries in their statistical systems.  On the SPI overall score itself, the countries scoring in the top 20% have an average SPI overall score of `r spi_top`.  A maximum score of 100 would indicate that a country has every single element in place that we measure through our indicators.  Meanwhile, countries in the bottom 20% score significantly worse, with an average index scores of `r spi_bottom`.  To highlight a few specific indicators, we can also see that countries in the top 20% on average get nearly perfect scores in terms of the debt reporting to the World Bank.  The top 20% of countries in the SPI overall score have an average score on their debt reporting of `r debt_top`, with a maximum score of 1 and minimum score of 0, while those in the bottom 20% on the SPI overall score have an average score of `r debt_bottom`.  To take another concrete example, when looking at scores on whether a population census has been conducted recently, countries in the top 20% score on average `r census_top` on our population census indicator, with a max score of 1 and minimum score of 0, while those in the bottom 20% on our SPI overall score receive `r census_bottom` points on the population census indicator.  The table below shows differences across maturity groups for a select set of indicators.


```{r maturitdisp}

maturity_tab <- maturity_tab %>%
  flextable() %>%
  add_header_lines('Select SPI Indicator Scores by SPI Maturity Level') 

FitFlextableToPage(maturity_tab) %>%
  align( align = "left", part = "body")

```


## SPI Overall Score by Region and Income Group

There are large differences in the SPI overall score across World Bank regions and income groups.  Overall, North America has the highest average SPI overall score, while the Sub-Saharan Africa region has the lowest average score.^[All tables and figures show unweighted summary statistics (i.e. the summary statistics do not weight by population).] There is also a clear gradient with respect to income groups.  Countries classified as low income have lower scores on average than countries classified as middle income.  High income countries have the highest average SPI overall score score.  

Finally, when looking over time, since 2016 the SPI overall score values are relatively stable across regions.  There has been some modest increase in the SPI overall score scores for middle income and high income countries, with little progress for low income countries.

Figure 5.2.
```{r spi_charts}
#show map and summary stats by region and income group

spi_charts('spi_index_df','SPI.INDEX','SPI Overall Score')

```


```{r regionheterogeneity}
#LAC
lac_df <- spi_index_df %>%
  filter(date==2019) %>%
  filter(region=="Latin America & Caribbean") %>%
  select(country, SPI.INDEX) %>%
  filter(!is.na(SPI.INDEX))

top_lac <- as.character(lac_df[1,1])
top_lac_score <- round(as.numeric(lac_df[1,2]),1)

bottom_lac <- as.character(lac_df[nrow(lac_df),1])
bottom_lac_score <- round(as.numeric(lac_df[nrow(lac_df),2]),1)

#SSA
ssa_df <- spi_index_df %>%
  filter(date==2019) %>%
  filter(region=="Sub-Saharan Africa") %>%
  select(country, SPI.INDEX) %>%
  filter(!is.na(SPI.INDEX))

top_ssa <- as.character(ssa_df[1,1])
top_ssa_score <- round(as.numeric(ssa_df[1,2]),1)

bottom_ssa <- as.character(ssa_df[nrow(ssa_df),1])
bottom_ssa_score <- round(as.numeric(ssa_df[nrow(ssa_df),2]),1)

#EAP
eap_df <- spi_index_df %>%
  filter(date==2019) %>%
  filter(region=="East Asia & Pacific") %>%
  select(country, SPI.INDEX) %>%
  filter(!is.na(SPI.INDEX))

top_eap <- as.character(eap_df[1,1])
top_eap_score <- round(as.numeric(eap_df[1,2]),1)

bottom_eap <- as.character(eap_df[nrow(eap_df),1])
bottom_eap_score <- round(as.numeric(eap_df[nrow(eap_df),2]),1)

```

While there are large differences across regions, within regions there is significant variation in the SPI overall score.  For instance, in the Latin America & Caribbean World Bank region, `r top_lac` is the highest scoring country on the SPI overall score with a score of `r top_lac_score`.  However, `r bottom_lac`, the lowest scoring country in the region, earns a substantially lower score of `r bottom_lac_score`.  In Sub-Saharan Africa, the highest scoring country is `r top_ssa` with a score of `r top_ssa_score`, while the lowest scoring country is `r bottom_ssa` with a score of `r bottom_ssa_score`.  In the East Asia and Pacific region, the top scoring country is `r top_eap` with a score of `r top_eap_score`, while the lowest scoring country is `r bottom_eap` with a score of `r bottom_eap_score`.

Figure 5.3
```{r spicountrycharts}
#show map and summary stats by region and income group

spi_country_charts('spi_index_df','SPI.INDEX','SPI Overall Score')

```

## SPI Scores by Dimension

Next, we present the scores for each dimension that compose the SPI overall score (Data Use, Data Services, Data Products, Data Sources, and Data Infrastructure).  These figures can help show where/which dimension variation is coming from across countries and to see where countries may be struggling in specific areas.

We apply the same maturity classification approach and apply it to each dimension separately, where we classify countries into quintiles.  For each dimension, we show the maturity levels of countries in a world map and then proceed to discussing scores by region.

### Dimension 1: Data Use

In the figure below we show a world map displaying the maturity levels based on dimension 1 on data use.  Again, the maturity levels shown are based on the quintiles of the Dimension 1 sub-score.  Overall, the high income countries in North America and Europe tend to rate most highly along this dimension.  

```{r dimensionsplot1}

spi_mapper('spi_index_df','SPI.INDEX.DIM1','Dimension 1: Data Use Scores')



```

When looking by country, there is significant dispersion within regions.  It is also notable that several countries including the United States, Mexico, Finland, and Costa Rica, among others, receive the maximum possible score in this dimension of 100.  Several countries score the minimum score as well, including the Syrian Arab Republic, South Sudan, Namibia, and Nauru, among others.

```{r countrydimensionsplot1}

spi_country_charts('spi_index_df','SPI.INDEX.DIM1','Dimension 1: Data Use Scores')



```

```{r maturitytable1}

indicators<-c("SPI.INDEX.DIM1","SPI.D1.5.POV","SPI.D1.5.CHLD.MORT","SPI.D1.5.DT.TDS.DPPF.XP.ZS", "SPI.D1.5.SAFE.MAN.WATER", "SPI.D1.5.LFP")

maturity_tab <- spi_maturity_table('spi_index_df',indicators,2019) 

spi_top <- as.numeric(maturity_tab[1,2])
spi_bottom <- as.numeric(maturity_tab[1,6])

poverty_top <- as.numeric(maturity_tab[2,2])
poverty_bottom <- as.numeric(maturity_tab[2,6])

mort_top <- as.numeric(maturity_tab[3,2])
mort_bottom <- as.numeric(maturity_tab[3,6])

debt_top <- as.numeric(maturity_tab[4,2])
debt_bottom <- as.numeric(maturity_tab[4,6])

```


The table below shows the average score on each indicator in Dimension 1 by maturity group.  Countries in the top 20% possess nearly all of the components in Dimension 1, while countries in the bottom 20% are lacking in many areas.  Countries in the bottom 20% in terms of maturity on Dimension 1 have an average of `r poverty_bottom` on the comparable poverty estimate indicator, an average of `r mort_bottom` on the availability of under 5 mortality data, and an average of `r debt_bottom` on debt reporting.


```{r maturitdisp1}

maturity_tab <- maturity_tab %>%
  flextable() %>%
  add_header_lines('Select SPI Indicator Scores by SPI Dimension 1 Maturity Level') 

FitFlextableToPage(maturity_tab) %>%
  align( align = "left", part = "body")

```

### Dimension 2: Data Services

For dimension 2 on data services, again high income countries tend to score highest along this dimension.  India, Morocco, and the Philippines scored highly as well in this dimension. This dimension contains four indicators on quality of data releases, online accessibility, advisory and analytical services (not included due to lack of data), and the availability and use of data services.   

```{r dimensionsplot2}
spi_mapper('spi_index_df','SPI.INDEX.DIM2','Dimension 2: Data Services Scores')

```

The next figure shows the variation between countries within regions.  Again, there is substantial heterogeneity within regions on the Dimension 2 sub-score.

```{r countrydimensionsplot2}

spi_country_charts('spi_index_df','SPI.INDEX.DIM2','Dimension 2: Data Services Scores')



```
```{r maturitytable2}

indicators<-c("SPI.INDEX.DIM2","SPI.D2.1.GDDS",
              "SPI.D2.2.Machine.readable",      "SPI.D2.2.Non.proprietary",
              "SPI.D2.2.Download.options",      "SPI.D2.2.Metadata.available",
              "SPI.D2.2.Terms.of.use",          "SPI.D2.2.Openness.subscore",     "SPI.D2.4.NADA")

maturity_tab <- spi_maturity_table('spi_index_df',indicators,2019) 

spi_top <- as.numeric(maturity_tab[1,2])
spi_bottom <- as.numeric(maturity_tab[1,6])

sdds_top <- as.numeric(maturity_tab[2,2])
sdds_bottom <- as.numeric(maturity_tab[2,6])

open_top <- as.numeric(maturity_tab[8,2])
open_bottom <- as.numeric(maturity_tab[8,6])

machine_bottom <- as.numeric(maturity_tab[3,6])

nada_bottom <- as.numeric(maturity_tab[9,6])

```


In terms of specific indicators, the top 20% of countries in dimension 2 receive an average score of `r sdds_top` on our indicator measuring country adoption of the IMF's data dissemination standards, while those in the bottom 20% receive an average score of `r sdds_bottom`.  Countries in the bottom 20% receive an average data openness score, produced by Open Data Watch, of `r open_bottom`.  This indicator is made up of several sub-indicators including whether data is available in machine readable format, a non-proprietary format, has download options, metadata available, and terms of use.  For instance, in the bottom 20% of countries the score on whether data is available in a machine readable format is only `r machine_bottom` out of a maximum of 1.  Additionally, countries in the bottom 20% only score an average of `r nada_bottom` on our measure of whether metadata meeting the standards of the Database Documentation Initiative (DDI) is available on surveys conducted.^[For more information, see https://ddialliance.org/]



```{r maturitdisp2}

maturity_tab <- maturity_tab %>%
  flextable() %>%
  add_header_lines('Select SPI Indicator Scores by SPI Dimension 2 Maturity Level') 

FitFlextableToPage(maturity_tab) %>%
  align( align = "left", part = "body")

```

### Dimension 3: Data Products

For the data products dimension, we examine whether countries are reporting data to monitor the SDG goals.  For this dimension, indicators are produced using the UN Global SDG monitoring database. For each SDG indicator, we check whether a value is available within a five year window of the date.  For instance, for the date of 2019, we examine whether any value is available between the years 2015-2019.

For this indicator, there is a weaker relationship between a country's income level and their performance in this dimension.  No countries receive a maximum score of 100, which would indicate that they report on every SDG indicator at least once inside a 5 year window.  Additionally, no country scores 0, which would indicate that they have reported no information for any of the SDG indicators.

While it is conceivable that some countries may have data values for these indicators on their NSO websites, for instance, rather than posted on the UN Global SDG monitoring database, we took the perspective that to produce a data product that is full usable a country's national statistical system should provide that information in an internationally comparable way.  And we have judged countries accordingly.  Additionally, for countries that have not reported values for SDG monitoring, but do possess a value, a simple way to improve their score on this dimension would be to submit all of their indicators to the UN database.  For OECD countries, we didi supplement the UN SDG database with comparable data submitted to the OECD following the methodology in "Measuring Distance to the SDG Targets 2019: An Assessment of Where OECD Countries Stand" (https://www.oecd.org/sdd/measuring-distance-to-the-sdg-targets-2019-a8caf3fa-en.htm).  We chose to supplement the UN Global SDG monitoring database using this OECD database, because a clear methodology had been established to do so.  Even with this supplemental data from the OECD included, there is considerable room for improvement in reporting on the SDGs.

We exclude values that were produced by an international organization through modeling  We do include values that are either country reported, country adjusted, estimated, or is included as global monitoring data.  This is based on the UN SDG metadata.  For each value of the indicator, the responsible international agency has been requested to indicate whether the national data were adjusted, estimated, modeled or are the result of global monitoring. The “nature” of the data in the SDG database is determined as follows:

  * Country data (C): Produced and disseminated by the country (including data adjusted by the country to meet international standards);

  * Country data adjusted (CA): Produced and provided by the country, but adjusted by the international agency for international comparability to comply with internationally agreed standards, definitions and classifications;

  * Estimated (E): Estimated based on national data, such as surveys or administrative records, or other sources but on the same variable being estimated, produced by the international agency when country data for some year(s) is not available, when multiple sources exist, or when there are data quality issues;

  * Modeled (M): Modeled by the agency on the basis of other covariates when there is a complete lack of data on the variable being estimated;

  * Global monitoring data (G): Produced on a regular basis by the designated agency for global monitoring, based on country data. There is no corresponding figure at the country level.

```{r dimensionsplot3}
spi_mapper('spi_index_df','SPI.INDEX.DIM3','Dimension 3: Data Products Scores')

```

When looking at the country chart, again there is significant variability across countries.  


```{r aggdimensionsplot3}

spi_charts('spi_index_df','SPI.INDEX.DIM3','Dimension 3: Data Products Scores')



```

```{r countrydimensionsplot3}

spi_country_charts('spi_index_df','SPI.INDEX.DIM3','Dimension 3: Data Products Scores')



```


```{r maturitytable3}

indicators<-c("SPI.INDEX.DIM3","SPI.D3.1.POV",
              "SPI.D3.2.HNGR",
              "SPI.D3.3.HLTH",
              "SPI.D3.4.EDUC",
              "SPI.D3.5.GEND",
              "SPI.D3.6.WTRS",
              "SPI.D3.7.ENRG",
              "SPI.D3.8.WORK",
              "SPI.D3.9.INDY",
              "SPI.D3.10.NEQL",
              "SPI.D3.11.CITY",
              "SPI.D3.12.CNSP",
              "SPI.D3.15.LAND",
              "SPI.D3.16.INST",
              "SPI.D3.17.PTNS")

maturity_tab <- spi_maturity_table('spi_index_df',indicators,2019) 

spi_top <- as.numeric(maturity_tab[1,2])
spi_bottom <- as.numeric(maturity_tab[1,6])

goal1_top <- as.numeric(maturity_tab[2,2])
goal1_bottom <- as.numeric(maturity_tab[2,6])

open_top <- as.numeric(maturity_tab[8,2])
open_bottom <- as.numeric(maturity_tab[8,6])

machine_bottom <- as.numeric(maturity_tab[3,6])

nada_bottom <- as.numeric(maturity_tab[9,6])

```


Even countries in the top 20% of this indicator have significant room for improvement in reporting on the SDGs.  The average score for the top 20% on the dimension 3 sub-score is `r spi_top`, while for the bottom 20% the average is `r spi_bottom`.  When looking at the performance for a specific goals, for SDG 1 on poverty, the top 20% in terms of the dimension 3 sub-score receives an average of `r goal1_top` out of a maximum of 1.  Specifically, this means that when looking at reporting on SDG goals in a five year window since 2019, so from 2015-19, the top performing countries are only reporting on `r 100*goal1_top` percent of the SDG indicators.  The bottom 20% receive an average score of `r goal1_bottom`.  The table below shows the full set of breakdowns by SDG.



```{r maturitdisp3}

maturity_tab <- maturity_tab %>%
  flextable() %>%
  add_header_lines('Select SPI Indicator Scores by SPI Dimension 2 Maturity Level') 

FitFlextableToPage(maturity_tab) %>%
  align( align = "left", part = "body")

```



```{r index_3alt, eval=FALSE, include=FALSE}



#################
# Nested Index with high income, OECD coutries top coded
################
  spi_index_df_dim3_alt <- spi_index_df_temp %>%
  arrange(country, date) %>%
  group_by(country) %>%
  mutate(across(starts_with("SPI"), na.locf, na.rm=FALSE)) %>%
  select(country, iso3c, date, everything()) %>%
  mutate(across(starts_with("SPI.D3"),
                ~if_else(( (income=='High income')  & (country %in% oecd_country_df$name)),1,.)                )) 



#Create overall subscores corresponding to John's framework
  spi_index_df_dim3_alt <- spi_index_df_dim3_alt %>%
    mutate(INDEX.SPI.D2.1=rowMeans(across(starts_with('SPI.D2.1'))),
         INDEX.SPI.D2.2=SPI.D2.2.Openness.subscore,
         INDEX.SPI.D2.4=SPI.D2.4.NADA,
         INDEX.SPI.D3.1=rowMeans(across(c("SPI.D3.1.POV",
                                            "SPI.D3.2.HNGR",
                                            "SPI.D3.3.HLTH",
                                            "SPI.D3.4.EDUC",
                                            "SPI.D3.5.GEND",
                                            "SPI.D3.6.WTRS"))),
         INDEX.SPI.D3.2=rowMeans(across(c("SPI.D3.7.ENRG",
                                            "SPI.D3.8.WORK",
                                            "SPI.D3.9.INDY",
                                            "SPI.D3.10.NEQL",
                                            "SPI.D3.11.CITY",
                                            "SPI.D3.12.CNSP"))),         
         INDEX.SPI.D3.3=rowMeans(across(c("SPI.D3.13.CLMT",
                                            "SPI.D3.15.LAND" ))),
         INDEX.SPI.D3.4=rowMeans(across(c("SPI.D3.16.INST",
                                            "SPI.D3.17.PTNS" ))),
         INDEX.SPI.D4.1=rowMeans(across(starts_with('SPI.D4.1'))),
         INDEX.SPI.D4.2=rowMeans(across(starts_with('SPI.D4.2'))),
         INDEX.SPI.D4.3=rowMeans(across(starts_with('SPI.D4.3'))),
         #INDEX.SPI.D5.1=rowMeans(across(starts_with('SPI.D5.1'))),
         INDEX.SPI.D5.2=rowMeans(across(starts_with('SPI.D5.2'))),
         #INDEX.SPI.D5.5=rowMeans(across(starts_with('SPI.D5.5')))
                 ) %>%
  mutate(
         SPI.INDEX.DIM1=rowMeans(across(starts_with("SPI.D1.5")), na.rm=FALSE),
         SPI.INDEX.DIM2=rowMeans(across(starts_with("INDEX.SPI.D2")), na.rm=FALSE),
         SPI.INDEX.DIM3.ALT=(6*INDEX.SPI.D3.1 + 6*INDEX.SPI.D3.2 + 2*INDEX.SPI.D3.3 + 2*INDEX.SPI.D3.4)/16,
         SPI.INDEX.DIM4=rowMeans(across(starts_with("INDEX.SPI.D4")), na.rm=FALSE),
         SPI.INDEX.DIM5=rowMeans(across(starts_with("INDEX.SPI.D5")), na.rm=FALSE),
         SPI.INDEX.ALT=rowMeans(across(c('SPI.INDEX.DIM1',
                                     'SPI.INDEX.DIM2',
                                     'SPI.INDEX.DIM3.ALT',
                                     'SPI.INDEX.DIM4',
                                     'SPI.INDEX.DIM5')), na.rm=FALSE)
         ) %>% #
  mutate(across(starts_with('SPI.INDEX'),~100*.)) %>%
  arrange(-date, -SPI.INDEX.ALT) %>%
  select(country, iso3c, date, starts_with('SPI.INDEX'), everything()) %>%
    filter(date>=2016) #2016 is first year with complete data


#################
# Nested Index with high income coutries top coded
################
  spi_index_df_dim3_alt2 <- spi_index_df_temp %>%
  arrange(country, date) %>%
  group_by(country) %>%
  mutate(across(starts_with("SPI"), na.locf, na.rm=FALSE)) %>%
  select(country, iso3c, date, everything()) %>%
  mutate(across(starts_with("SPI.D3"),
                ~if_else(( (income=='High income')  ),1,.)                )) 



#Create overall subscores corresponding to John's framework
  spi_index_df_dim3_alt2 <- spi_index_df_dim3_alt2 %>%
    mutate(INDEX.SPI.D2.1=rowMeans(across(starts_with('SPI.D2.1'))),
         INDEX.SPI.D2.2=SPI.D2.2.Openness.subscore,
         INDEX.SPI.D2.4=SPI.D2.4.NADA,
         INDEX.SPI.D3.1=rowMeans(across(c("SPI.D3.1.POV",
                                            "SPI.D3.2.HNGR",
                                            "SPI.D3.3.HLTH",
                                            "SPI.D3.4.EDUC",
                                            "SPI.D3.5.GEND",
                                            "SPI.D3.6.WTRS"))),
         INDEX.SPI.D3.2=rowMeans(across(c("SPI.D3.7.ENRG",
                                            "SPI.D3.8.WORK",
                                            "SPI.D3.9.INDY",
                                            "SPI.D3.10.NEQL",
                                            "SPI.D3.11.CITY",
                                            "SPI.D3.12.CNSP"))),         
         INDEX.SPI.D3.3=rowMeans(across(c("SPI.D3.13.CLMT",
                                            "SPI.D3.15.LAND" ))),
         INDEX.SPI.D3.4=rowMeans(across(c("SPI.D3.16.INST",
                                            "SPI.D3.17.PTNS" ))),
         INDEX.SPI.D4.1=rowMeans(across(starts_with('SPI.D4.1'))),
         INDEX.SPI.D4.2=rowMeans(across(starts_with('SPI.D4.2'))),
         INDEX.SPI.D4.3=rowMeans(across(starts_with('SPI.D4.3'))),
         #INDEX.SPI.D5.1=rowMeans(across(starts_with('SPI.D5.1'))),
         INDEX.SPI.D5.2=rowMeans(across(starts_with('SPI.D5.2'))),
         #INDEX.SPI.D5.5=rowMeans(across(starts_with('SPI.D5.5')))
                 ) %>%
  mutate(
         SPI.INDEX.DIM1=rowMeans(across(starts_with("SPI.D1.5")), na.rm=FALSE),
         SPI.INDEX.DIM2=rowMeans(across(starts_with("INDEX.SPI.D2")), na.rm=FALSE),
         SPI.INDEX.DIM3.ALT2=(6*INDEX.SPI.D3.1 + 6*INDEX.SPI.D3.2 + 2*INDEX.SPI.D3.3 + 2*INDEX.SPI.D3.4)/16,
         SPI.INDEX.DIM4=rowMeans(across(starts_with("INDEX.SPI.D4")), na.rm=FALSE),
         SPI.INDEX.DIM5=rowMeans(across(starts_with("INDEX.SPI.D5")), na.rm=FALSE),
         SPI.INDEX.ALT2=rowMeans(across(c('SPI.INDEX.DIM1',
                                     'SPI.INDEX.DIM2',
                                     'SPI.INDEX.DIM3.ALT2',
                                     'SPI.INDEX.DIM4',
                                     'SPI.INDEX.DIM5')), na.rm=FALSE)
         ) %>% #
  mutate(across(starts_with('SPI.INDEX'),~100*.)) %>%
  arrange(-date, -SPI.INDEX.ALT2) %>%
  select(country, iso3c, date, SPI.INDEX.ALT2,SPI.INDEX.DIM3.ALT2, income) %>%
    mutate(weights=1) %>%
    filter(date>=2016) #2016 is first year with complete data
 
#merge the two indices and compare  
index_compare <- spi_index_df_dim3_alt %>%
  transmute(
    country=country,
    iso3c=iso3c,
    date=date,
    SPI.INDEX.ALT=SPI.INDEX.ALT
  ) %>%
  filter(date==2019) %>%
  filter(!is.na(SPI.INDEX.ALT)) %>%
  left_join(select(spi_index_df, country, date, SPI.INDEX) ) %>%
  left_join(spi_index_df_dim3_alt2) %>%
  select(-SPI.INDEX.DIM3.ALT2,-income)

    spi_groups_quantiles <- quantile(index_compare$SPI.INDEX, probs=c(1,2,3,4)/5,na.rm=T)
    spi_alt_groups_quantiles <- quantile(index_compare$SPI.INDEX.ALT, probs=c(1,2,3,4)/5,na.rm=T)
    spi_alt2_groups_quantiles <- quantile(index_compare$SPI.INDEX.ALT2, probs=c(1,2,3,4)/5,na.rm=T)

    index_compare <- index_compare %>%
      mutate(spi_groups=case_when(
        between(SPI.INDEX, spi_groups_quantiles[4],100) ~ "Top 20%",
        between(SPI.INDEX, spi_groups_quantiles[3],spi_groups_quantiles[4]) ~ "4th Quintile",
        between(SPI.INDEX, spi_groups_quantiles[2],spi_groups_quantiles[3]) ~ "3rd Quintile",
        between(SPI.INDEX, spi_groups_quantiles[1],spi_groups_quantiles[2]) ~ "2nd Quintile",
        between(SPI.INDEX, 0,spi_groups_quantiles[1]) ~ "Bottom 20%"
      )) %>%
      mutate(spi_groups=factor(spi_groups, 
                               levels=c("Top 20%","4th Quintile","3rd Quintile","2nd Quintile","Bottom 20%" )))  %>%
      mutate(spi_alt_groups=case_when(
        between(SPI.INDEX.ALT, spi_alt_groups_quantiles[4],100) ~ "Top 20%",
        between(SPI.INDEX.ALT, spi_alt_groups_quantiles[3],spi_alt_groups_quantiles[4]) ~ "4th Quintile",
        between(SPI.INDEX.ALT, spi_alt_groups_quantiles[2],spi_alt_groups_quantiles[3]) ~ "3rd Quintile",
        between(SPI.INDEX.ALT, spi_alt_groups_quantiles[1],spi_alt_groups_quantiles[2]) ~ "2nd Quintile",
        between(SPI.INDEX.ALT, 0,spi_alt_groups_quantiles[1]) ~ "Bottom 20%"
      )) %>%
      mutate(spi_alt_groups=factor(spi_alt_groups, 
                               levels=c("Top 20%","4th Quintile","3rd Quintile","2nd Quintile","Bottom 20%" ))) %>%
      mutate(spi_alt2_groups=case_when(
        between(SPI.INDEX.ALT2, spi_alt2_groups_quantiles[4],100) ~ "Top 20%",
        between(SPI.INDEX.ALT2, spi_alt2_groups_quantiles[3],spi_alt2_groups_quantiles[4]) ~ "4th Quintile",
        between(SPI.INDEX.ALT2, spi_alt2_groups_quantiles[2],spi_alt2_groups_quantiles[3]) ~ "3rd Quintile",
        between(SPI.INDEX.ALT2, spi_alt2_groups_quantiles[1],spi_alt2_groups_quantiles[2]) ~ "2nd Quintile",
        between(SPI.INDEX.ALT2, 0,spi_alt2_groups_quantiles[1]) ~ "Bottom 20%"
      )) %>%
      mutate(spi_alt2_groups=factor(spi_alt2_groups, 
                               levels=c("Top 20%","4th Quintile","3rd Quintile","2nd Quintile","Bottom 20%" ))) %>%
      mutate(weights=1)


```

```{r index_compare_plot, eval=FALSE, include=FALSE}


spi_charts('spi_index_df_dim3_alt', 'SPI.INDEX.DIM3.ALT','Dimension 3: Data Products - OECD High Income Top Coded')


```

```{r index_compare_plot2, eval=FALSE, include=FALSE}


spi_charts('spi_index_df_dim3_alt2', 'SPI.INDEX.DIM3.ALT2','Dimension 3: Data Products - All High Income Top Coded')


```

### Dimension 4: Data Sources

Dimension 4 examines whether countries have the data sources available that are necessary to produce statistics for public use.  We examine three aspects of data sources: censuses and surveys, administrative data, and geospatial data.  Private and citizen generated data is another important area that we will incorporate when we are able make use of an established source.  For the censuses and surveys we examine, we score on both whether this source exists and how recently the source was produced, as both are needed for accurate reporting of current conditions.  For administrative data and geospatial data, we are using proxies available on the state of these data systems.



```{r dimensionsplot4}
spi_mapper('spi_index_df','SPI.INDEX.DIM4','Dimension 4: Data Sources Scores')
```


When looking at the country chart, again there is significant variability across countries.  No country receives the maximum score of 100, with many countries falling short particularly on our geospatial indicator.  Somalia is the only country that receives 0 points on this indicator, which is the minimum score.

```{r countrydimensionsplot4}

spi_country_charts('spi_index_df','SPI.INDEX.DIM4','Dimension 4: Data Sources Scores')



```


```{r maturitytable4}

indicators<-c("SPI.INDEX.DIM4",
              "SPI.D4.1.1.POPU",
              "SPI.D4.1.2.AGRI",
              "SPI.D4.1.3.BIZZ",
              "SPI.D4.1.4.HOUS",
              "SPI.D4.1.5.AGSVY",
              "SPI.D4.1.6.LABR",
              "SPI.D4.1.7.HLTH",
              "SPI.D4.1.8.BZSVY",
              "SPI.D4.2.3.CRVS",
              "SPI.D4.3.GEO.first.admin.level")

maturity_tab <- spi_maturity_table('spi_index_df',indicators,2019) 

spi_top <- as.numeric(maturity_tab[1,2])
spi_bottom <- as.numeric(maturity_tab[1,6])

pop_top <- as.numeric(maturity_tab[2,2])
pop_bottom <- as.numeric(maturity_tab[2,6])
pop_gap <- pop_top-pop_bottom

business_gap <- as.numeric(maturity_tab[9,2])-as.numeric(maturity_tab[9,6])

geo_top <- as.numeric(maturity_tab[11,2])
geo_bottom <- as.numeric(maturity_tab[11,6])


```


Countries in the top 20% for dimension 4 have an average score of `r spi_top`, while countries in the bottom 20% have an average score of `r spi_bottom`.  The gap between the top 20% and bottom 20% for the population and housing census indicator is `r pop_gap` points on a scale from 0 to 1.  The gap for countries conducting a business/establishment survey is `r business_gap`.  The scores for even top performing countries on our geospatial indicator are low.  The average score for the top 20% in dimension 4 is `r geo_top`, while it is `r geo_bottom` for the bottom 20%.

```{r maturitdisp4}

maturity_tab <- maturity_tab %>%
  flextable() %>%
  add_header_lines('Select SPI Indicator Scores by SPI Dimension 4 Maturity Level') 

FitFlextableToPage(maturity_tab) %>%
  align( align = "left", part = "body")

```

### Dimension 5: Data Infrastructure

The fifth dimension measures whether countries have the hard and soft infrastructure to produce the data sources, data products, and data services to produce useful data.  For the dimension 5 sub-score, we use only a set of ten methods, standards, and classifications.  We also have collected data on statistical legislation and governance, as well as finance, but these indicators currently lack adequate country coverage to include in our index.


```{r maturitytable5}

indicators<-c("SPI.INDEX.DIM5",
              #"SPI.D5.1.DILG",
              "SPI.D5.2.1.SNAU",
              "SPI.D5.2.2.NABY",
              "SPI.D5.2.3.CNIN",
              "SPI.D5.2.4.CPIBY",
              "SPI.D5.2.5.HOUS",
              "SPI.D5.2.6.EMPL",
              "SPI.D5.2.7.CGOV",
              "SPI.D5.2.8.FINA",
              "SPI.D5.2.9.MONY",
              "SPI.D5.2.10.GSBP")
              #"SPI.D5.5.DIFI")

maturity_tab <- spi_maturity_table('spi_index_df',indicators,2019) 

spi_top <- as.numeric(maturity_tab[1,2])
spi_bottom <- as.numeric(maturity_tab[1,6])



```

Countries scoring in the top 20% tend to be concentrated among the high income countries.  These top scoring countries have an average score for dimension 5 of `r spi_top`, which is near the maximum score of 100.  Countries in the bottom 20% have an average score fo `r spi_bottom`.

```{r dimensionsplot5}
spi_mapper('spi_index_df','SPI.INDEX.DIM5','Dimension 5: Data Infrastructure Scores')

```

Several countries score the maximum of 100 in the data infrastructure dimension.  One country, Somalia, scores 0 points in this dimension.  

```{r countrydimensionsplot5}

spi_country_charts('spi_index_df','SPI.INDEX.DIM5','Dimension 5: Data Infrastructure Scores')



```

In the top 20%, the average score is near 100 across all the indicators in dimension 5.  In the bottom 20%, countries score on average close to zero points for the CPI base year, classification of status of employment, central government accounting status, compilation of government finance statistics, and business process indicators.  Bottom 20% countries, score above 0.5 points on the system of national accounts in use and compilation of monetary and financial statistics indicators.


```{r maturitdisp5}

maturity_tab <- maturity_tab %>%
  flextable() %>%
  add_header_lines('Select SPI Indicator Scores by SPI Dimension 5 Maturity Level') 

FitFlextableToPage(maturity_tab) %>%
  align( align = "left", part = "body")

```

### Correlations between SPI Dimensions

In the following chart, we show the correlations between the SPI overall score and the SPI dimension sub-scores.  All dimensions are positively correlated with one another.  On the other hand, no dimension is perfectly correlated with any of the other dimensions, which would be a sign that a dimension was not provide additional information on the statistical performance of countries.  The dimension with the single highest correlation to the overall measure is dimension 1 on data use.  The indicator with the lowest overall correlation with the SPI overall score is dimension 3 on data products.

```{r dimcorr, echo=FALSE}

corr_df <- spi_index_df %>%
  ungroup() %>%
  select(starts_with('SPI.INDEX'))

#calculate correlations between teacher practices
df_corr_plot <-    round(cor(corr_df, use="complete.obs"), 2) 

#plot the correlation in a nicely formatted table
pcorr<- ggcorrplot::ggcorrplot(df_corr_plot,
                   outline.color = "white",
                   ggtheme = theme_bw(),
                   colors = c("#F8696B", "#FFEB84", "#63BE7B"),
                   legend.title = "Correlation",
                   title = "Correlation Between SPI Dimensions",
                   lab=T) + 
  scale_x_discrete(labels = function(x) str_wrap(x, width = 12)) +
  scale_y_discrete(labels = function(x) str_wrap(x, width = 16)) +
  theme_bw() +
  theme(
    text = element_text(size = 12),
    axis.text.x = element_text(angle=45,vjust=.5)
  ) +
  labs( )

pcorr

```

## SPI Scores by Pillar and Indicator

While there are large differences across regions, income groups, and countries in the SPI overall score, there are also differences across indicators in the strengths and weaknesses of countries that may have the same final score.  For instance, some countries may reach a final score by excelling in the area of data sources, while others may reach a final score by excelling in data infrastructure.  While there are many paths that countries may take to reaching an SPI overall score and only by studying the pillars and indicators for a particular country in detail can you understand why a country gets a particular score, we can at least characterize which of the pillars and indicators are most responsible for differences between countries.

In order to do so, we apply a leave-out approach to calculating our SPI overall scores, which can help us understand which pillars and indicators are most impactful.  The leave-out approach is similar in spirit to a jackknife approach (see [@miller1974jackknife] for an introduction), which has been used in a variety of situations to examine the sensitivity of estimates to leaving out specific observations. Specifically for our case, the leave-out approach consists of sequentially deleting indicators one at a time and recalculating the SPI overall scores.  By sequentially omitting indicators, we can calculate the total difference between the SPI overall score incorporating all indicators and an alternative SPI score that is calculated by omitting a single indicator.  We can then rank our pillars and indicators based on which produce the greatest total difference between our SPI overall score and the alternative score.

Specifically, the approach is as follows:   

1. Calculate the SPI overall score for each country using all pillars and indicators, $SPI.INDEX_{c}$.    
  
2. For each indicator $j=1,...,J$ do:   
  
  + Generate an alternative SPI score omitting indicator $j$, $SPI.INDEX^{-j}_{c}$.    
    
  + Calculate difference between the original score and the alternative score for each country in a year $t$, $e_{c}^{-j}=SPI.INDEX_{c}-SPI.INDEX^{-j}_{c}$ 
    
  + Calculate the mean absolute difference across all countries, $E^{-j}=\sum_{c=1}^{N_c} |e_{c}^{-j}|/C$ 
    
3. Sort indicators based on $E^{-j}$.


```{r leave_out, include=FALSE}

leave_out_fun <-  function(variables) {
  
spi_index_df_alt <- spi_index_df_temp %>%
  arrange(country, date) %>%
  group_by(country) %>%
  mutate(across(starts_with("SPI"), na.locf, na.rm=FALSE)) %>%
  mutate(across(starts_with(variables),~as.numeric(NA))) %>% #convert selected variable to missing values then begin calculation without them
  select(country, iso3c, date, everything())



#Create overall subscores corresponding to John's framework
spi_index_df_alt <- spi_index_df_alt %>%
  mutate(INDEX.SPI.D2.1=rowMeans(across(starts_with('SPI.D2.1'))),
         INDEX.SPI.D2.2=SPI.D2.2.Openness.subscore,
         INDEX.SPI.D2.4=SPI.D2.4.NADA,
         INDEX.SPI.D3.1=rowMeans(across(c("SPI.D3.1.POV",
                                          "SPI.D3.2.HNGR",
                                          "SPI.D3.3.HLTH",
                                          "SPI.D3.4.EDUC",
                                          "SPI.D3.5.GEND",
                                          "SPI.D3.6.WTRS")), na.rm=TRUE),
         INDEX.SPI.D3.2=rowMeans(across(c("SPI.D3.7.ENRG",
                                          "SPI.D3.8.WORK",
                                          "SPI.D3.9.INDY",
                                          "SPI.D3.10.NEQL",
                                          "SPI.D3.11.CITY",
                                          "SPI.D3.12.CNSP")), na.rm=TRUE),         
         INDEX.SPI.D3.3=rowMeans(across(c("SPI.D3.13.CLMT",
                                          "SPI.D3.15.LAND" )), na.rm=TRUE),
         INDEX.SPI.D3.4=rowMeans(across(c("SPI.D3.16.INST",
                                          "SPI.D3.17.PTNS" )), na.rm=TRUE),
         INDEX.SPI.D4.1=rowMeans(across(starts_with('SPI.D4.1')), na.rm=TRUE),
         INDEX.SPI.D4.2=rowMeans(across(starts_with('SPI.D4.2')), na.rm=TRUE),
         INDEX.SPI.D4.3=rowMeans(across(starts_with('SPI.D4.3')), na.rm=TRUE),
         #INDEX.SPI.D5.1=rowMeans(across(starts_with('SPI.D5.1'))),
         INDEX.SPI.D5.2=rowMeans(across(starts_with('SPI.D5.2')), na.rm=TRUE),
         #INDEX.SPI.D5.5=rowMeans(across(starts_with('SPI.D5.5')))
  ) %>%
  mutate(
    SPI.INDEX.DIM1=rowMeans(across(starts_with("SPI.D1.5")), na.rm=TRUE),
    SPI.INDEX.DIM2=rowMeans(across(starts_with("INDEX.SPI.D2")), na.rm=TRUE),
    SPI.INDEX.DIM3=(6*INDEX.SPI.D3.1 + 6*INDEX.SPI.D3.2 + 2*INDEX.SPI.D3.3 + 2*INDEX.SPI.D3.4)/16,
    SPI.INDEX.DIM4=rowMeans(across(starts_with("INDEX.SPI.D4")), na.rm=TRUE),
    SPI.INDEX.DIM5=rowMeans(across(starts_with("INDEX.SPI.D5")), na.rm=TRUE),
    SPI.INDEX.ALT=rowMeans(across(c('SPI.INDEX.DIM1',
                                    'SPI.INDEX.DIM2',
                                    'SPI.INDEX.DIM3',
                                    'SPI.INDEX.DIM4',
                                    'SPI.INDEX.DIM5')), na.rm=TRUE)
  ) %>% #
  mutate(across(starts_with('SPI.INDEX'),~100*.)) %>%
  arrange(-date, -SPI.INDEX.ALT) %>%
  select(country, iso3c, date, SPI.INDEX.ALT) %>%
  filter(date>=2016) #2016 is first year with complete data

  #form database with both measures
  spi_index_df %>%
    select(country, iso3c, date, SPI.INDEX) %>%
    left_join(spi_index_df_alt) %>%
    ungroup() %>%
    summarise(mean_abs_diff=mean(abs(SPI.INDEX-SPI.INDEX.ALT), na.rm=T))

  
}

leave_out_df <- metadata_full %>%
  filter(!grepl('SPI.INDEX|RAW.',source_id)) %>%
  nest(source_id) %>%
  mutate(
    ABS.DIFF=map(
      data,
      ~leave_out_fun(.x$source_id)
    )
  ) %>%
  unnest(ABS.DIFF)


```


```{r leaveoutplot, fig.height=15, fig.width=10}

leave_out_df %>%
  mutate(descript=str_wrap(paste(SPI_indicator_id,": ", source_name , sep=""),55)) %>%
  filter(mean_abs_diff>0) %>%
  arrange(mean_abs_diff) %>%
  mutate(descript=factor(descript, levels=descript)) %>%
  ggplot(aes(x=descript, y=mean_abs_diff, color=SPI_indicator_id)) +
    geom_segment( aes(x=descript ,xend=descript, y=0, yend=mean_abs_diff)) +
    geom_point(size=3) +
    geom_text(aes(label=round(mean_abs_diff,2)),color='black', nudge_y=.2) +
    coord_flip() +
    theme_bw() +
    theme(
      panel.grid.minor.y = element_blank(),
      panel.grid.major.y = element_blank(),
      legend.position = 'none'
    ) +
    xlab("") +
    ylab("Mean Absolute Difference") +
    labs(
      title="SPI Indicator Importance",
      subtitle = "Mean absolute difference in SPI overall scores leaving out indicator",
      caption="The leave-out approach consists of sequentially deleting pillars or indicators one at a time and recalculating the SPI overall scores."
    )

```

The indicator that drives the single largest difference between the SPI overall score and an alternative score omitting the indicator is the civil registration and vital statistics (CRVS) indicator in Pillar 4.2 on administrative data.  This is closely followed by the indicator on whether NADA metadata is provided as a data service.  The indicators creating the smallest difference when omitted tend to the be the individual indicators in dimension 3 on data products.  The indicator with the single smallest difference is in Pillar 3:10 on SDG 10.


```{r anova, eval=FALSE, include=FALSE}

#Analysis of variance.  In the analysis below, I will calculate the variance in each dimension and in each pillar.

anova_dim_df <- spi_index_df %>%
  select(country, iso3c, date, starts_with("SPI.INDEX")) %>%
  pivot_longer(
    cols=starts_with("SPI.INDEX"),
    names_to='Dimension',
    values_to='value'
  ) %>%
  group_by(Dimension, date) %>%
  nest() %>%
  mutate(
    std_dev=map(
      data,
      ~round(sd(.x$value, na.rm=T),2),
                ),
    std_dev=as.numeric(std_dev)
  ) %>%
  left_join(metadata_full, by = c('Dimension'='source_id'))
  

anova_dim_plot <- anova_dim_df %>%
  filter(date==2019) %>%
  ggplot(aes(x=source_name, y=std_dev))  +
  geom_segment( aes(x=source_name ,xend=source_name, y=0, yend=std_dev), color="black") +
  geom_point(size=3) +
  # scale_color_manual(name="HCI",
  #                    labels = c("Over-performers", "Under-performers"),
  #                    values = c('above'="#1A9850", 'below'="#D73027")) +
  coord_flip() +
  theme_bw() +
  theme(
    panel.grid.minor.y = element_blank(),
    panel.grid.major.y = element_blank(),
    legend.position = 'bottom'
  ) +
  xlab("") +
  ylab("Standard Deviation") +
  ggtitle("Variation in SPI Dimensions")

anova_dim_plot

```

```{r anova2, eval=FALSE, include=FALSE}

#Analysis of variance.  In the analysis below, I will calculate the variance in each dimension and in each pillar.

anova_pillar_df <- spi_index_df %>%
  mutate(INDEX.SPI.D1.5=SPI.INDEX.DIM1/100) %>%
  select(country, iso3c, date, starts_with("INDEX")) %>%
  pivot_longer(
    cols=starts_with("INDEX"),
    names_to='Pillar',
    values_to='value'
  ) %>%
  group_by(Pillar, date) %>%
  nest() %>%
  mutate(
    std_dev=map(
      data,
      ~round(sd(.x$value, na.rm=T),2)
        ),
    std_dev=as.numeric(std_dev)
  ) %>%
  left_join(pillars, by = c('Pillar'='pillar_id'))
  
    
anova_pillar_plot <- anova_pillar_df %>%
  filter(date==2019) %>%
  ggplot(aes(x=Pillar, y=std_dev))  +
  geom_segment( aes(x=Pillar ,xend=Pillar, y=0, yend=std_dev), color="black") +
  geom_point(size=3) +
  # scale_color_manual(name="HCI",
  #                    labels = c("Over-performers", "Under-performers"),
  #                    values = c('above'="#1A9850", 'below'="#D73027")) +
  coord_flip() +
  theme_bw() +
  theme(
    panel.grid.minor.y = element_blank(),
    panel.grid.major.y = element_blank(),
    legend.position = 'bottom'
  ) +
  xlab("") +
  ylab("Standard Deviation") +
  ggtitle("Variation in SPI Pillars")

anova_pillar_plot  

```


# Analysis

## Unique Values

```{r unique_scores}

#calculate the number of unique values in the SPI Index
spi_index_2019 <- spi_index_df %>%
  filter(date==2019) %>%
  filter(!is.na(SPI.INDEX))

unique_scores <-  length(unique(spi_index_2019$SPI.INDEX))

#check unique values by dimension.
unique_scores1 <-  length(unique(spi_index_2019$SPI.INDEX.DIM1))
unique_scores2 <-  length(unique(spi_index_2019$SPI.INDEX.DIM2))
unique_scores3 <-  length(unique(spi_index_2019$SPI.INDEX.DIM3))
unique_scores4 <-  length(unique(spi_index_2019$SPI.INDEX.DIM4))
unique_scores5 <-  length(unique(spi_index_2019$SPI.INDEX.DIM5))

```


As a check of the data, we calculate the number of unique scores for our SPI overall score. If our SPI overall score produces a large number of tied scores, for instance, then our index will be less able to distinguish between the statistical performance of countries.  When calculating the number of unique values for 2019, we find that there are `r unique_scores` unique scores for `r n_countries` countries.  This means there are `r n_countries-unique_scores` tied values.  When looking within each dimension.  

When looking at each specific dimension, there are only `r unique_scores1` unique scores for Dimension 1 on data use.  The data use indicator is coming solely from dimension 1.5 on data use by international organizations.  For Dimension 2, there are `r unique_scores2` unique scores.  For Dimension 3, there are `r unique_scores3` unique scores.  There are `r unique_scores4` unique scores for dimension 4, and there are `r unique_scores5` unique scores for dimension 5.




## Relationship to GDP Per Capita and the Human Capital Index

Below, we will present the correlation between our SPI overall score and the log of GDP per capita and the World Bank's Human Capital Index ([@hci2020]).  These relationships are meant as a face validity check between our index and other outcomes.  This analysis is not meant to necessarily establish a causal relationship, only to assess whether our index is correlated with other outcomes in ways we would expect.  The source for GDP per capita comes from the  World Bank's World Development Indicators (WDI) database (NY.GDP.PCAP.KD).  The GDP per capita numbers are in constant 2010 US$.  

```{r log_gdp}

#HCI
hci_df <- wbstats::wb_data(country="countries_only", 
              indicator='HD.HCI.OVRL',
              start_date=2016,
              end_date=2019,
              return_wide = F) %>%
  left_join(select(spi_index_df,iso3c,date, region,starts_with('SPI.INDEX'))) #merge on SPI Index data

#get the correlation for 2019
hci_df_2018 <- hci_df %>%
  filter(date==2018) 




hci_spi <- ggplot(data=hci_df_2018, aes(x=value, y=SPI.INDEX)) +
  facet_wrap(~indicator) +
  geom_text(aes(label=iso3c)) +
  geom_smooth(method='lm') +
  theme_bw() +
  ylab('SPI Overall Score') +
  xlab('Human Capital Index') +
  stat_poly_eq(aes(label  = paste(stat(eq.label),
                                stat(rr.label), sep = "*\", \"*")), 
                     label.x.npc = "right", label.y.npc = 0.1,
                     formula = 'y~x', parse = TRUE, size = 4) +
    theme(legend.position = 'bottom')


#GDP
gdp_df <- wbstats::wb_data(
  indicator='NY.GDP.PCAP.KD',
  start_date=2016,
  end_date=2019,
  return_wide = F
    ) %>%
  left_join(select(spi_index_df,iso3c,date, region,starts_with('SPI.INDEX'))) #merge on SPI Index data

#get the correlation for 2019
gdp_df_2019 <- gdp_df %>%
  filter(date==2019) 

  gdp_spi <- ggplot(data=gdp_df_2019, aes(x=value, y=SPI.INDEX)) +
  facet_wrap(~indicator) +
  geom_text(aes(label=iso3c)) +
  geom_smooth(method='lm') +
  scale_x_log10(labels = scales::comma) +
  theme_bw() +
  ylab('SPI Overall Score') +
  xlab('Log GDP Per Capita') +
  theme(legend.position = 'bottom') +
  stat_poly_eq(aes(label = paste(stat(eq.label),
                                stat(rr.label), sep = "*\", \"*")), 
                     label.x.npc = "right", label.y.npc = 0.1,
                     formula = 'y~x', parse = TRUE, size = 4)
  




corr_hci_2018 <- cor(hci_df_2018$value,hci_df_2018$SPI.INDEX, use='pairwise.complete.obs')


corr_2019 <- cor(log(gdp_df_2019$value),gdp_df_2019$SPI.INDEX, use='pairwise.complete.obs')
corr_2019_nontrans <- cor(gdp_df_2019$value,gdp_df_2019$SPI.INDEX, use='pairwise.complete.obs')

```

We would expect a strong positive relationship between GDP per capita of countries and their statistical system, as higher income countries would tend to have more resources available for statistical production.  In fact, there is a strong relationship between the two.  The correlation in 2019 between log GDP per capita and the SPI overall score is `r round(corr_2019,2)`.[^1]

[^1]: To understand what effect taking the log has on this correlation, the correlation in 2019 between (non-logged) GDP per capita and the SPI overall score is `r round(corr_2019_nontrans,2)`. 

Another measure of a country's development is the Human Capital Index (HCI) developed by the World Bank ([@hci2020]).  The Human Capital Index is designed to capture the amount of human capital a child born today can expect to attain by age 18 in a country.  The index combines a country's child mortality, learning adjusted years of schooling, adult survival rates & stunting into one index. For more details, visit the Human Capital Index website (https://www.worldbank.org/en/publication/human-capital).  Again, we would expect a strong positive relationship between a country's HCI value and their Statistical Performance Indicators index value, as countries with a more developed human capital stock are likely to have greater capacity to produce statistics.  Again, this is what we see.  The correlation between the 2018 value of the HCI (the latest value available at the time of this writing) and the 2018 value of the SPI overall score is `r round(corr_hci_2018,2)`.

Below we show the scatter plot of the relationship between log GDP per capita, the HCI, and our SPI overall score for the years 2016-2019.  In general, countries with higher per capita income and higher levels of human capital tend to have better performing statistical systems according to our measure.  

```{r gdpplot}

### Scatterplot log GDP SPI
gdp_spi + hci_spi   +
  plot_annotation(
    title='Plot of SPI overall score on Human Capital Index and GDP per capita',
    caption='Source: All indicators come from the World Bank.'
    )
  

```

So as to highlight countries where this relationships do not hold as well, the next figure shows the 15 countries that most over-perform and the 15 countries that most under-perform on the SPI Index compared to their levels of GDP per capita and the Human Capital Index.  We would  not necessarily expect a perfect fit between our SPI overall score and GDP per capita and the Human Capital Index, as countries differ in the resources put into their statistical system, even conditional on their levels of development.  Highlighting outliers can sometimes be a useful exercise for determining whether a measure is identifying on the ground realities.  

In order to produce this figure, we estimate an OLS regression of the SPI overall score in 2019 on log GDP per capita.  We then calculate the residual, which can be interpreted as the difference between the country's SPI overall score value and the expected index value based on their GDP per capita.  Countries with values of the residual greater than zero are over-performing based on their GDP per capita and countries with residuals less than zero are under-performing.  The corresponding figure for the Human Capital Index is calculated similarly, however in this case we do not take the log, as we did with GDP per capita.

```{r overperformers}

#get top 10 and bottom 10 over performers compared to gdp and hci

## GDP
#regress SPI on gdp

indicator <- 'SPI.INDEX'

form <- paste(indicator, " ~ log(value)", sep="")

m_spi <- lm(form , data = gdp_df_2019) 

gdp_overperformers_df <- gdp_df_2019 %>%
  modelr::add_residuals(m_spi) %>%
  arrange(-resid) %>%
  head(15)

gdp_underperformers_df <- gdp_df_2019 %>%
  modelr::add_residuals(m_spi) %>%
  arrange(resid) %>%
  head(15)


gdp_overperformers_plot <-  gdp_overperformers_df %>%
  bind_rows(gdp_underperformers_df) %>%
  arrange(resid) %>%
  mutate(country=factor(country, levels=country),
         group=if_else(resid>=0, 'above','below')) %>%
  ggplot(aes(x=country, y=resid, color=group)) +
  geom_segment( aes(x=country ,xend=country, y=0, yend=resid), color="black") +
  geom_point(size=3) +
  scale_color_manual(name="GDP per Capita",
                     labels = c("Over-performers", "Under-performers"),
                     values = c('above'="#1A9850", 'below'="#D73027")) +
  coord_flip() +
  theme_bw() +
  theme(
    panel.grid.minor.y = element_blank(),
    panel.grid.major.y = element_blank(),
    legend.position = 'bottom'
  ) +
  xlab("") +
  ylab("SPI (deviation)") +
  ggtitle("GDP per capita")



### HCI


#regress SPI on hci
m_spi_hci <- lm(form , data = hci_df_2018) 

hci_overperformers_df <- hci_df_2018 %>%
  modelr::add_residuals(m_spi_hci) %>%
  arrange(-resid) %>%
  head(15)

hci_underperformers_df <- hci_df_2018 %>%
  modelr::add_residuals(m_spi_hci) %>%
  arrange(resid) %>%
  head(15)

hci_overperformers_plot <-  hci_overperformers_df %>%
  bind_rows(hci_underperformers_df) %>%
  arrange(resid) %>%
  mutate(country=factor(country, levels=country),
         group=if_else(resid>=0, 'above','below')) %>%
  ggplot(aes(x=country, y=resid, color=group)) +
  geom_segment( aes(x=country ,xend=country, y=0, yend=resid), color="black") +
  geom_point(size=3) +
  scale_color_manual(name="HCI",
                     labels = c("Over-performers", "Under-performers"),
                     values = c('above'="#1A9850", 'below'="#D73027")) +
  coord_flip() +
  theme_bw() +
  theme(
    panel.grid.minor.y = element_blank(),
    panel.grid.major.y = element_blank(),
    legend.position = 'bottom'
  ) +
  xlab("") +
  ylab("SPI (deviation)") +
  ggtitle("Human Capital Index")



gdp_overperformers_plot + hci_overperformers_plot +
  plot_annotation(title='Top 15 Over/Under-Performers on SPI overall score compared to GDP per capita and Human Capital Index',
                  caption=str_wrap('Over and under performers calculated for GDP per capita by using OLS regression of SPI overall score in 2019 on Log GDP per capita and calculting residuals from this regression.  Over and Under performers for Human Capital Index calculated similarly.',100)
                  )
```


## Relationship to Government Effectiveness

```{r ge}

#HCI
ge_df <- wbstats::wb_data(country="countries_only", 
              indicator=c('GE.EST','NY.GDP.PCAP.KD', 'GE.PER.RNK'),
              start_date=2016,
              end_date=2019,
              return_wide = T) %>%
  left_join(select(spi_index_df,iso3c,date, region,starts_with('SPI.INDEX'))) #merge on SPI Index data

#get the correlation for 2019
ge_df_2019 <- ge_df %>%
  filter(date==2019) 


corr_ge <- cor(ge_df_2019$GE.EST,ge_df_2019$SPI.INDEX, use='pairwise.complete.obs')



ge_spi <- lm_robust(GE.EST ~ SPI.INDEX + log(NY.GDP.PCAP.KD) + factor(date) + factor(region) , data = ge_df, se_type = "HC2") 

ge_spi_tidy <- broom::tidy(ge_spi)
ge_spi_glance <- broom::glance(ge_spi)

#get effect of SPI
spi_eff <- ge_spi_tidy %>%
  filter(term=='SPI.INDEX')
spi_eff <- spi_eff$estimate
```


A common justification for improving statistical systems is that doing so can lead to better governance. Without good statistics, countries may be flying blind on where to target resources to improve the public welfare.  Also, good statistics can help hold public officials accountable for progress toward reaching a country's goals. In this next section, we show the relationship between our SPI overall score and an estimate of government effectiveness produced by the Worldwide Governance Indicators (WGI).  We find a strong relationship between our measure of statistical performance and the WGI measure of governmental effectiveness.

[@kraay2010worldwide] produce a set of Worldwide Governance Indicators, including a measure of government effectiveness.  According to the WGI metadata, the government effectiveness indicator captures perceptions of the quality of public services, the quality of the civil service and the degree of its independence from political pressures, the quality of policy formulation and implementation, and the credibility of the government's commitment to such policies. The estimate gives the country's score on the aggregate indicator, in units of a standard normal distribution, i.e. ranging from approximately -2.5 to 2.5.^[Detailed documentation of the WGI, interactive tools for exploring the data, and full access to the underlying source data available at www.govindicators.org. The WGI are produced by Daniel Kaufmann (Natural Resource Governance Institute and Brookings Institution) and Aart Kraay (World Bank Development Research Group).].  The government effectiveness indicator is available from 1996 to 2019.

There is a strong relationship between the SPI overall score and the government effectivenss indicator.  The correlation between the two in 2019 is `r round(corr_ge,2)`.  The scatterplot below shows the relationship between the SPI overall score and the government effectivenss indicator.





```{r geplot}
ge_spi_plot <- ggplot(data=ge_df_2019, aes(x=GE.EST, y=SPI.INDEX)) +
  geom_text(aes(label=iso3c)) +
  geom_smooth(method='lm') +
  theme_bw() +
  ylab('SPI Overall Score') +
  xlab('Government Effectiveness Score (z score)') +
  stat_poly_eq(aes(label  = paste(stat(eq.label),
                                stat(rr.label), sep = "*\", \"*")), 
                     label.x.npc = "right", label.y.npc = 0.1,
                     formula = 'y~x', parse = TRUE, size = 4) +
    theme(legend.position = 'bottom') +
  labs(
    title='Plot of SPI overall score on Government Effectiveness',
    caption='Source: All indicators come from the World Bank.  Government Effectiveness indicator comes from Worldwide Governance Indicators.'
  )


ge_spi_plot

```


To tease out to what extent the relationship between the government effectiveness indicator and the SPI is due to other factors such as income or regional characteristics, we present results from an OLS regression below.  While we acknowledge that a more detailed study could be conducted to better understand the processes relating the two, we do find a relationship between government effectiveness and statistical performance after accounting for income and regional characteristics of a country.

The regression model we use takes the following form:

$$ G_{ctr} = \alpha_t + \gamma_r + \beta SPI.INDEX_{ctr} + \theta X_{ctr} + \epsilon_{ctr} $$

where $Y_{ctri}$ is the government effectiveness estimate for country i, in time period t, and region r.  $SPI.INDEX_{ctri}$ is the SPI overall score. $X_{ctri}$ is a set of control variables in the regression. This includes log GDP per capita from the World Bank WDI. $\epsilon_{ctri}$ is the error term.  $\alpha_t$ is an indicator variable for each year and  $\gamma_r$ is a regional indicator variable.

The table below shows the estimate of $\beta$, the effect of the statistical performance measure on government effectiveness.  Full results from this regression are shown in a table in the appendix.  The estimated coefficient is statistically significant at the 0.1% level, and implies that a 10 point increase in the SPI overall score is associated with a `r round(10*spi_eff,2)` standard deviation increase in government effectiveness.  For context, this 10 point jump in the SPI would roughly take a country from roughly the median in terms of government effectiveness to roughly the 58th percentile.




```{r geregsmall, echo=FALSE}
# 





#fix labels
factor_names <- grep("factor", names(coef(ge_spi)), value = TRUE)
names(factor_names) <- gsub(".*)(.)", "\\1", factor_names)


#create table
huxtable::huxreg('Goverment Effectiveness'=ge_spi,
       coefs=c('SPI Overall Score'='SPI.INDEX'),
       note='{stars}. \nRegression also includes log GDP per capita, year indicator variables, and region indicator variables as controls.  \n Heteroskedasticity robust standard errors in parenthesis.',
       number_format=3,
       bold_signif=0.05) %>%
  #huxtable::set_caption('Linear Regressions of Changes in Government Effectiveness on Changes in SPI from 2016-19') %>%
  huxtable::as_flextable() %>%
  add_header_lines('Linear Regressions of Government Effectiveness Score on SPI Overall Score from 2016-19') %>%
  FitFlextableToPage() %>%
  width(width = 2.5)

```

## Country Changes in the Index



```{r changes}
#create a dataframe for the 2016 SPI to calculate changes since 2016
spi_index_2016 <- spi_index_df %>%
  filter(date==2016) %>%
  filter(!is.na(SPI.INDEX)) %>%
  mutate(SPI.INDEX.2016=SPI.INDEX) %>%
  select(iso3c, country, region, SPI.INDEX.2016)

spi_changes <- spi_index_2019 %>%
  mutate(SPI.INDEX.2019=SPI.INDEX) %>%
  select(iso3c, country,region, SPI.INDEX.2019) %>%
  left_join(spi_index_2016)


#correlation
corr_2019_2016 <- cor(spi_changes$SPI.INDEX.2019,spi_changes$SPI.INDEX.2016, use='pairwise.complete.obs')


```

In order to assess how stable our index values are over time, next we will compare the index values in 2016 to the 2019 values.  Overall, the SPI overall score is quite stable over time.  The correlation between the 2016 value and the 2019 value is `r round(corr_2019_2016,2)`.

```{r changesplot}

ggplot(spi_changes, aes(x=SPI.INDEX.2016, y=SPI.INDEX.2019, color=region)) +
  geom_text(aes(label=iso3c)) +
  geom_smooth(method='lm', color='blue') +
  geom_segment(aes(x=10,xend=100, y=10,yend=100), color='grey') +
  expand_limits(x=c(10,100),y=c(10,100)) +
  theme_bw() +
  labs(
    title='Scatterplot of 2019 SPI overall score  & 2016 SPI overall score',
    caption = 'Solid grey line represents the 45 degree line.  Blue line represents line of best fit (regression line) with a 95% confidence interval shown in a shaded line.'
  ) +
  ylab('2019 SPI Overall Score') +
  xlab('2016 SPI Overall Score') +
  theme(legend.position = 'bottom') +
    stat_poly_eq(aes(label = paste(stat(eq.label),
                                stat(rr.label), sep = "*\", \"*")), 
                     color='black',
                     label.x.npc = "right", label.y.npc = 0.1,
                     formula = 'y~x', parse = TRUE, size = 4) +
  guides(
    size="none"
  )


```


```{r top_bottom_changes}

top_changes <- spi_changes %>%
  mutate(changes=SPI.INDEX.2019-SPI.INDEX.2016) %>%
  arrange(-abs(changes)) %>%
  select(country,SPI.INDEX.2019,SPI.INDEX.2016, changes) %>%
  mutate(across(c('SPI.INDEX.2019','SPI.INDEX.2016', 'changes'),round,1))

top_mover <- as.character(top_changes[1,1])
top_mover_change <- as.numeric(top_changes[1,4])
```


While the scores were relatively stable over time, some countries did see large improvements in their score from 2016-2019.  The country that improved most on our index from 2016 to 2019 was `r top_mover`. `r top_mover` improved by `r top_mover_change` points on our scale out of 100.  The table below shows the changes in our SPI overall score for the top 10 largest improvers.



```{r topbottomchangestab}
top_changes_tab <- flextable(head(top_changes,10)) %>%
  add_header_lines('Top 10 Countries with Largest Changes from 2016-2019.') %>%
  set_header_labels(values=list(
                       country="Country",
                       SPI.INDEX.2019="SPI Overall Score 2019",
                       SPI.INDEX.2016="SPI Overall Score 2016",
                       changes="Difference"
                                   )) 

FitFlextableToPage(top_changes_tab) %>%
  width(width=1.2) %>%
  align( align = "left", part = "body")
```



## Density Plots

As another check, we present the distribution of scores across countries for each year and compare this distribution to a normal distribution.  This exercise checks for whether the distribution of our SPI overall scores contains significant skew or fat tails.  There is some indication of a bunching of scores near the top of the distribution of SPI scores.  This is due to a large number of OECD countries possessing similar scores on our index.  This is not unexpected as OECD requires member countries to adhere to several methodological standards and  to regularly report on a large set of indicators.  These countries also are composed of several of the highest income countries that tend to be on the frontier of statistical production.



```{r comparison, include=FALSE}

#pull SCI values

Request_metadata <- GET(url = "http://api.worldbank.org/v2/country/all/indicator/IQ.SCI.OVRL?format=json&date=2004:2020&per_page=5000")
Response_metadata <- content(Request_metadata, as = "text", encoding = "UTF-8")

# Parse the JSON content and convert it to a data frame.
sci_df <- jsonlite::fromJSON(Response_metadata, flatten = TRUE) %>%
  data.frame() %>%
  transmute(
    iso3c=countryiso3code,
    country=country.value,
    date=as.numeric(date),
    SCI=value
  ) %>%
  left_join(spi_df_empty) %>% #add on country metadata
  filter(!is.na(income)) %>%
  select(iso3c, country, date, SCI  ) %>%
  group_by(date) %>%
  arrange(-SCI) %>%
  mutate(SCI_rank=rank(-SCI),
         SCI_rank=if_else(is.na(SCI),as.numeric(NA),SCI_rank))


#check unique values by dimension.
unique_scores_df <- sci_df %>% filter(date==2019) %>% mutate(SCI=round(SCI,3))
unique_scores_sci <-length(unique(unique_scores_df$SCI))



#read in ODIN data
  for (i in 2015:2018) {
   temp <- read_csv(paste(raw_dir, '/2.2_DSOA/','ODIN_',i,'.csv', sep=""))  %>%
        as_tibble(.name_repair = 'universal') %>%
        mutate(date=i) %>%
        filter(Data.categories=='All Categories')


    assign(paste('odin_df',i,sep="_"), temp)
  }

    #bind different years together
odin_df <- bind_rows(odin_df_2015, odin_df_2016, odin_df_2017, odin_df_2018)


odin_df <- odin_df %>%
    select(Country.Code, date, Overall.score) %>%
    rename(iso3c=Country.Code,
           ODIN_score=Overall.score) %>%
    group_by(date) %>%
    arrange(-ODIN_score) %>%
    mutate(ODIN_rank=rank(-ODIN_score, na.last='NA')) %>% 
  right_join(spi_df_empty) %>%
  arrange(country, date) %>%
  group_by(country) %>%
  mutate(across(starts_with("ODIN"), na.locf, na.rm=FALSE)) %>%
  select(country, date, starts_with("ODIN"))


#read in the old SPI
SPI_v0_df <- readxl::read_excel(path='C:/Users/wb469649/OneDrive - WBG/DECIS/SPI_AKI/Data/FinalCopy of SPI SCORE 2016-2018-DW.xlsx', skip=2) %>%
  transmute(
    iso3c=Country,
    SPI_2016=as.numeric(Overall...7),
    SPI_2017=as.numeric(Overall...12),
    SPI_2018=as.numeric(Overall...17)
  ) %>%
  pivot_longer(
    cols=c('SPI_2016','SPI_2017','SPI_2018'),
    names_to="date",
    values_to = 'SPI_v0'
  ) %>%
  mutate(date=gsub('SPI_','',date),
         date=as.numeric(date))


#create one database
comparison_df <- spi_index_df %>%
  ungroup() %>%
  filter(date %in% c(2016:2019)) %>%
  arrange(-SPI.INDEX) %>%
  mutate(across(starts_with('SPI.INDEX'),~1*.),
         across(starts_with('SPI.INDEX'),round,1)) %>%
  select(country, iso3c, date, income, region, SPI.INDEX) %>%
  left_join(sci_df) %>%
  left_join(odin_df) %>%
  left_join(SPI_v0_df)




```


```{r density}

density_df <- comparison_df %>%
  select(iso3c, date, SPI.INDEX, SPI_v0, ODIN_score, SCI) %>%
  pivot_longer(
    cols = c('SPI.INDEX', 'SPI_v0', 'ODIN_score', 'SCI'),
    names_to='index',
    values_to='index_values'
  ) %>%
  mutate(
    index_name=case_when(
      index=='SPI.INDEX' ~ "SPI overall score",
      index=='SPI_v0' ~ "SPI Index Version 0",
      index=='ODIN_score' ~ "Open Data Watch",
      index=='SCI' ~ "SCI",
      
    )
  )

#show the density of our SPI index
ggplot(spi_index_df, aes(x = SPI.INDEX)) + 
  facet_wrap(~date) +
  geom_histogram( 
                          aes(y=..density.., fill=..count..)) +
  stat_function(fun = dnorm, 
                color='red',
                args = list(mean = mean(spi_index_df$SPI.INDEX, na.rm=T), sd = sd(spi_index_df$SPI.INDEX, na.rm=T))) +
    theme_bw() +
  labs(
    title='Distribution of SPI overall score across Countries',
    color='Index Name'
  ) +
  xlab('SPI overall score') +
  theme(legend.position = 'bottom')



```

```{r density2}
#show the density of our SPI index compared to other indices
ggplot(density_df, aes(x = index_values, color=index_name)) + 
  facet_wrap(~date) +
  geom_density() +
    theme_bw() +
  labs(
    title='Distribution of SPI overall score and alternative indices across countries',
    color='Index Name'
  ) +
  xlab('Index value') +
  theme(legend.position = 'bottom')
```

# Conclusion

The new Statistical Performance Indicators (SPI) will replace the Statistical Capacity Index (SCI), which the World Bank has regularly published since 2004.  Although the goals are the same, to be a tool to measure the statistical systems of countries, the new SPI has expanded into new areas including on data use, administrative data, geospatial data, data services, and data infrastructure.  The SPI provides a forward looking framework that can help countries measure where they stand in several dimensions and offers an ambitious measurement agenda for the international community.

The goals are to offer a framework that was forward looking, measured less mature statistical systems as well as advanced systems, covered the entire national statistical system, not just the National Statistical Office (NSO), and gives countries incentives to build a modern statistical system.  We also are committing to making our project open data and open code to build confidence in our work.  The data will also be updated on a yearly basis to track progress over time.

More research and data collection is needed particularly in terms of data use.  And while we feel that our framework is comprehensive, we readily admit that our specific indicators measuring each pillar and dimension can be improved.  We hope one of the functions of our dashboard is as a call to arms for the international community to better measure these areas.

<!-- We identify five key dimensions of a country’s statistical performance. These are data use, data services, data products, data sources, and data infrastructure . These dimensions can be presented in the form of a dashboard that can help countries identify areas for development in their statistical system. Improvements in performance can be represented as a virtuous data cycle that can become self-sustaining. -->

Countries and international organizations need to know each national statistical system's current capabilities, and the new SPI is meant to help fill this gap.  Only then can the virtuous cycle of investment, effectiveness, innovation, value added and impact can begin.




# Annex

## Country SPI overall scores

Below, we present the full list of countries by their SPI overall score in 2019.  The first column is the country name and the following columns are the overall SPI overall score, and then the sub-scores for dimension 1,2,3,4 and 5.  

The cells in the table are color coded based on the performance of countries on our index and the sub-scores of the dimensions.  Given the imprecision inherent in the calculations we recommend that the color coding provides the most detailed subdivisions of maturity. Finer distinctions are unlikely to provide meaningful differentiation between countries. 

Countries shaded in dark red are the lowest performing, countries in dark green are the highest performing.  Countries are grouped into five groups:   

* **Top 20%**:  Countries in the top 20% are classified in this group.  Shading in <span style="color:#2ec4b6">dark green</span>.    
* **4th Quantile**: Countries in the 4th quantile, or those above the 60th percentile but below the 80th percentile are in this group.  Shading in <span style="color:#acece7">light green</span>.    
* **3rd Quantile**: Countries in the 3rd quantile, or those between the 40th and 60th percentile, are classified in this group.  Shading in <span style="color:#f1dc76">yellow</span>.  
* **2nd Quantile**: Countries in the 2nd quantile, or those above the 20th percentile but below the 40th percentile, are in this group.  Shading in <span style="color:#ffbf69">light orange</span>.  
* **Bottom 20%**: Countries in the bottom 20% are classified in this group.  Shading in <span style="color:#ff9f1c">dark orange </span>.  




```{r tab1, echo=FALSE}


#colors

col_palette <- c("#2ec4b6", "#acece7", "#f1dc76",  "#ffbf69","#ff9f1c"   )

col_palette2 <- c("#2ec4b6",  "#f1dc76", "#ff9f1c" )

#make the table
index_tab <- index_disp %>%
  filter(date==2019) %>%
  select(country, SPI.INDEX,SPI.INDEX.DIM1,SPI.INDEX.DIM2,SPI.INDEX.DIM3,SPI.INDEX.DIM4,SPI.INDEX.DIM5) 

 #calculate the breaks for the color coding
        brks <- quantile(index_tab$SPI.INDEX, probs=c(1,2,3,4)/5,na.rm=T)
        brks <- append(0,brks)
        brks <- append(brks,100)

        brks1 <- quantile(index_tab$SPI.INDEX.DIM1, probs=c(1,2,3,4)/5,na.rm=T)
        brks1 <- append(0,brks1)
        if (max(brks1)<100) brks1 <- append(brks1,100)
        
        brks2 <- quantile(index_tab$SPI.INDEX.DIM2, probs=c(1,2,3,4)/5,na.rm=T)
        brks2 <- append(0,brks2)
        if (max(brks2)<100) brks2 <- append(brks2,100)
        
        brks3 <- quantile(index_tab$SPI.INDEX.DIM3, probs=c(1,2,3,4)/5,na.rm=T)
        brks3 <- append(0,brks3)
        if (max(brks3)<100) brks3 <- append(brks3,100)
        
        brks4 <- quantile(index_tab$SPI.INDEX.DIM4, probs=c(1,2,3,4)/5,na.rm=T)
        brks4 <- append(0,brks4)
        if (max(brks4)<100) brks4 <- append(brks4,100)
        
        brks5 <- quantile(index_tab$SPI.INDEX.DIM5, probs=c(1,2,3,4)/5,na.rm=T)
        brks5 <- append(0,brks5)
        if (max(brks5)<100) brks5 <- append(brks5,100)
        

      #make nice looking
      index_tab <- index_tab %>%
        flextable() %>%
        add_header_lines('SPI overall score in 2019 and Dimension Scores.') %>%
        set_header_labels(values=list(
                             country="Country",
                             SPI.INDEX="SPI overall score",
                             SPI.INDEX.DIM1="Dim 1: Data Use",
                             SPI.INDEX.DIM2="Dim 2: Data Services",
                             SPI.INDEX.DIM3="Dim 3: Data Products ",
                             SPI.INDEX.DIM4="Dim 4: Data Sources",
                             SPI.INDEX.DIM5="Dim 5: Data Infrastructure"
                                         )) %>%
          bg(j = c('SPI.INDEX'),
             bg = scales::col_bin(col_palette, domain=c(0,100), bins=brks, reverse=TRUE)) %>%
          bg(j = c('SPI.INDEX.DIM1'),
             bg = scales::col_bin(col_palette, domain=c(0,100), bins=brks1, reverse=TRUE)) %>%
          bg(j = c('SPI.INDEX.DIM2'),
             bg = scales::col_bin(col_palette, domain=c(0,100), bins=brks2, reverse=TRUE)) %>%
          bg(j = c('SPI.INDEX.DIM3'),
             bg = scales::col_bin(col_palette, domain=c(0,100), bins=brks3, reverse=TRUE)) %>%
          bg(j = c('SPI.INDEX.DIM4'),
             bg = scales::col_bin(col_palette, domain=c(0,100), bins=brks4, reverse=TRUE)) %>%
          bg(j = c('SPI.INDEX.DIM5'),
             bg = scales::col_bin(col_palette, domain=c(0,100), bins=brks5, reverse=TRUE))
# 
# #make nice looking
# index_tab <- index_tab %>%
#   flextable() %>%
#   add_header_lines('SPI overall score in 2019 and Dimension Scores.') %>%
#   set_header_labels(values=list(
#                        country="Country", 
#                        SPI.INDEX="SPI overall score",
#                        SPI.INDEX.DIM1="Dim 1: Data Use",
#                        SPI.INDEX.DIM2="Dim 2: Data Services",
#                        SPI.INDEX.DIM3="Dim 3: Data Products ",
#                        SPI.INDEX.DIM4="Dim 4: Data Sources",
#                        SPI.INDEX.DIM5="Dim 5: Data Infrastructure"
#                                    )) %>%
#     bg(j = c('SPI.INDEX'), 
#        bg = scales::col_quantile(col_palette, domain=NULL, n=5, reverse=TRUE)) %>%
#     bg(j = c('SPI.INDEX.DIM1'),
#        bg = scales::col_quantile(col_palette, domain=NULL, n=5, reverse=TRUE)) %>%
#     bg(j = c('SPI.INDEX.DIM2'),
#        bg = scales::col_quantile(col_palette, domain=NULL, n=5, reverse=TRUE)) %>%
#     bg(j = c('SPI.INDEX.DIM3'),
#        bg = scales::col_quantile(col_palette, domain=NULL, n=5, reverse=TRUE)) %>%
#     bg(j = c('SPI.INDEX.DIM4'),
#        bg = scales::col_quantile(col_palette, domain=NULL, n=5, reverse=TRUE)) %>%
#     bg(j = c('SPI.INDEX.DIM5'),
#        bg = scales::col_quantile(col_palette, domain=NULL, n=5, reverse=TRUE))
# 
#   

FitFlextableToPage(index_tab)

```
## Country SPI overall scores over time


```{r tabtime, echo=FALSE}


#colors
col_palette <- c("#2ec4b6", "#acece7", "#f1dc76",  "#ffbf69","#ff9f1c"   )

col_palette2 <- c("#2ec4b6",  "#f1dc76", "#ff9f1c" )

#make the table
index_tab_time <- spi_index_df %>%
  select(country, date, SPI.INDEX) %>%
  mutate(SPI.INDEX=round(SPI.INDEX,1)) %>%
  filter(!is.na(SPI.INDEX)) %>%
  pivot_wider(
    names_from=date,
    values_from=SPI.INDEX,
    names_prefix='SPI.INDEX.'
  )

#make nice looking
index_tab_time <- index_tab_time %>%
  flextable() %>%
  add_header_lines('SPI overall scores over time') %>%
  set_header_labels(values=list(
                       country="Country", 
                       SPI.INDEX.2019="2019",
                       SPI.INDEX.2018="2018",
                       SPI.INDEX.2017="2017",
                       SPI.INDEX.2016="2016"
                                   )) %>%
    bg(j = c('SPI.INDEX.2019'), 
       bg = scales::col_quantile(col_palette, domain=NULL, n=5, reverse=TRUE)) %>%
    bg(j = c('SPI.INDEX.2018'),
       bg = scales::col_quantile(col_palette, domain=NULL, n=5, reverse=TRUE)) %>%
    bg(j = c('SPI.INDEX.2017'),
       bg = scales::col_quantile(col_palette, domain=NULL, n=5, reverse=TRUE)) %>%
    bg(j = c('SPI.INDEX.2016'),
       bg = scales::col_quantile(col_palette, domain=NULL, n=5, reverse=TRUE)) 

  

FitFlextableToPage(index_tab_time)

```




```{r tabrecode, eval=FALSE, include=FALSE}


#colors
col_palette <- c("#2ec4b6", "#acece7", "#f1dc76",  "#ffbf69","#ff9f1c"   )

col_palette2 <- c("#2ec4b6",  "#f1dc76", "#ff9f1c" )

#make the table
index_tab_recode <- index_compare %>%
  mutate(SPI.INDEX=round(SPI.INDEX,1),
         SPI.INDEX.ALT=round(SPI.INDEX.ALT,1),
         SPI.INDEX.ALT2=round(SPI.INDEX.ALT2,1)) %>%
  select(country, SPI.INDEX, spi_groups, SPI.INDEX.ALT, spi_alt_groups, SPI.INDEX.ALT2, spi_alt2_groups)
#make nice looking
index_tab_recode <- index_tab_recode %>%
  flextable() %>%
  add_header_lines('SPI overall scores over time') %>%
  set_header_labels(values=list(
                       country="Country", 
                       SPI.INDEX="SPI Overall Score",
                       spi_groups="SPI Maturity Grouping",
                       SPI.INDEX.ALT="SPI Overall Score: Top Coding OECD High Income Countries for Dimension 3.",
                       spi_alt_groups="SPI Maturity Grouping: Top Coding OECD High Income",
                       SPI.INDEX.ALT2="SPI Overall Score: Top Coding All High Income Countries for Dimension 3.",
                       spi_alt2_groups="SPI Maturity Grouping: Top Coding All High Income"
                                   )) %>%
    bg(j = c('SPI.INDEX'), 
       bg = scales::col_quantile(col_palette, domain=NULL, n=5, reverse=TRUE)) %>%
    bg(j = c('spi_groups'),
       bg = scales::col_quantile(col_palette, domain=NULL, n=5, reverse=TRUE), source = 'SPI.INDEX') %>%
    bg(j = c('SPI.INDEX.ALT'), 
       bg = scales::col_quantile(col_palette, domain=NULL, n=5, reverse=TRUE)) %>%
    bg(j = c('spi_alt_groups'),
       bg = scales::col_quantile(col_palette, domain=NULL, n=5, reverse=TRUE), source = 'SPI.INDEX.ALT') %>%
    bg(j = c('SPI.INDEX.ALT2'), 
       bg = scales::col_quantile(col_palette, domain=NULL, n=5, reverse=TRUE)) %>%
    bg(j = c('spi_alt2_groups'),
       bg = scales::col_quantile(col_palette, domain=NULL, n=5, reverse=TRUE), source = 'SPI.INDEX.ALT2')   

FitFlextableToPage(index_tab_recode)

```

## Comparison to other measures of statistical performance

Next, we compare our index to several other indices of statistical performance that have been created.  This will provide a sense of how rankings differ across measures, how they correlate with other outcomes, and how the distributions of scores compare.  These are the SCI, the Open Data Watch index (ODIN), and version 0 of the SPI overall score that was produced in [@cameron2019measuring] 

We first compare the SPI overall score to the older World Bank Statistical Capacity Index (http://datatopics.worldbank.org/statisticalcapacity/SCIdashboard.aspx).  The correlation between the SPI overall score and the SCI  is `r round(cor(comparison_df$SPI.INDEX,comparison_df$SCI, use='pairwise.complete.obs'),3)`.

```{r sci}

### Scatterplot SCI SPI
spi_sci_plot <- ggplot(comparison_df, aes(y=SPI.INDEX,x=SCI, color=region)) +
  facet_wrap(~date) +
  # geom_point() +
  geom_text(aes(label=iso3c)) +
  theme_bw() +
  labs(
    title='Scatterplot of Statistical Capacity Index (SCI) and SPI Overall Score'
  ) +
  ylab('SPI Overall Score') +
  xlab('SCI value') +
  theme(legend.position = 'bottom')

spi_sci_plot


```


```{r scispireg}
gdp_reg_df <- wbstats::wb_data(
  indicator='NY.GDP.PCAP.KD',
  start_date=2016,
  end_date=2019
    ) %>%
  mutate(log_gdp_pcap=log(NY.GDP.PCAP.KD)) %>%
  left_join(select(comparison_df,iso3c,date, region,SPI.INDEX,SCI,ODIN_score,SPI_v0)) #merge on SPI Index data
  
  
#regress Log GDP SPI
m_spi <- lm_robust(SPI.INDEX ~ log_gdp_pcap + factor(date), data = gdp_reg_df, se_type = "HC2") 

m_spi_lm <- lm(SPI.INDEX ~ log_gdp_pcap + factor(date), data = filter(gdp_reg_df,!(is.na(SPI.INDEX) | is.na(log_gdp_pcap)))) 
gdp_reg_df_resids <- broom::augment(m_spi_lm, data=filter(gdp_reg_df,!(is.na(SPI.INDEX) | is.na(log_gdp_pcap)) ))


#regress Log GDP SCI
m_sci <- lm_robust(SCI ~ log_gdp_pcap + factor(date), data = gdp_reg_df, se_type = "HC2") 


#regress Log GDP ODIN
m_odin <- lm_robust(ODIN_score ~ log_gdp_pcap + factor(date), data = gdp_reg_df, se_type = "HC2") 


#regress Log GDP SPI_v0
m_spi_v0 <- lm_robust(SPI_v0 ~ log_gdp_pcap + factor(date), data = gdp_reg_df, se_type = "HC2") 

m_spi_tidy <- broom::tidy(m_spi)
m_spi_glance <- broom::glance(m_spi)

spi_coef <- as.numeric(m_spi_tidy[2,2])
spi_r2 <- as.numeric(m_spi_glance[1,1])

```


Next, we show how the relationship to Log GDP per capita differs for the SCI and the SPI overall score using linear regression.  We also include the Open Data Watch and the version of the Statistical Performance Index developed in [@cameron2019measuring].  While showing a strong relationship between an index and log GDP per capita does not mean the index is necessarily correct, and is certainly not necessarily causal, it does provide a face validity check of the index.  Heteroskedasticity robust standard errors are shown in the table.

Overall, the new SPI overall score has the strongest relationship to GDP per capita.  The linear regression estimates indicate that a 1% increase in GDP per capita is associated with a `r round(spi_coef/100,1)` point increase in our SPI overall score.  The r-squared from this regression is `r round(spi_r2,2)`.



```{r scispiregtab}



#combine SPI and SCI results together
date_names <- grep("factor", names(coef(m_spi)), value = TRUE)
names(date_names) <- gsub(".*)(.)", "Year: \\1", date_names)

huxtable::huxreg('SPI overall score'=m_spi, 'SCI'=m_sci, 'Open Data Watch'=m_odin, 'SPI Version 0'=m_spi_v0,
       coefs=c('Log GDP per Capita'='log_gdp_pcap', date_names, 'Intercept'='(Intercept)'),
       note='{stars}. Heteroskedasticity Robust Std Errors in Parenthesis',
       number_format=2,
       bold_signif=0.05) %>%
  huxtable::set_caption('Linear Regressions of Alternate Statistical Performance Indices on Log GDP per Capita') %>%
  huxtable::as_flextable() %>%
  FitFlextableToPage() %>%
  width(width=1.2)



gdp_long <- gdp_reg_df %>%
  pivot_longer(
    cols = c('SPI.INDEX', 'SPI_v0', 'ODIN_score', 'SCI'),
    names_to='index',
    values_to='index_values'
  ) %>%
  mutate(
    index_name=case_when(
      index=='SPI.INDEX' ~ "SPI overall score",
      index=='SPI_v0' ~ "SPI Index Version 0",
      index=='ODIN_score' ~ "Open Data Watch",
      index=='SCI' ~ "SCI",
      
    )
  ) %>%
  filter(date==2018)

ggplot(gdp_long, aes(x=log_gdp_pcap,y=index_values, color=region)) +
  facet_wrap(~index_name) +
  # geom_point() +
  geom_text(aes(label=iso3c)) +
  theme_bw() +
  labs(
    title='Scatterplot of Alternate Statistical Performance Indices on Log GDP per Capita'
  ) +
  xlab('Log GDP Per Capita') +
  ylab('Index Values') +
  theme(legend.position = 'bottom')

```



We compare the SPI overall score to the Open Data Watch rankings of country statistical systems (https://odin.opendatawatch.com/report/rankings).  The correlation between the SPI overall score and the ODIN index is `r round(cor(comparison_df$SPI.INDEX,comparison_df$ODIN_score, use='pairwise.complete.obs'),3)`
 


```{r odin, echo=FALSE}

 

### Scatterplot ODIN SPI
spi_odin_plot <- ggplot(comparison_df, aes(y=SPI.INDEX,x=ODIN_score, color=region)) +
  # geom_point() +
  facet_wrap(~date) +
  geom_text(aes(label=iso3c)) +
  theme_bw() +
  labs(
    title='Scatterplot of SPI overall score on Open Data Watch Index'
  ) +
  ylab('SPI overall score') +
  xlab('ODIN value') +
  theme(legend.position = 'bottom')

spi_odin_plot




```



As a final comparison, we compare our new SPI overall score to an index developed by [@cameron2019measuring], which can be thought of as a version 0 of our SPI overall score.  The authors use similar data sources for their index.  However, there are some differences.


First, the similarities.  The methodology for constructing the index is the same.  Also, the censuses and surveys (Indicator 4.1) and standards and methods (Indicator 5.2) are identical.  The indicator for data releases (Indicator 2.1) and data services (Indicator 2.4) are pulled from the information collected in the fourth dimension on dissemination practices from version 0 of the SPI in Cameron et al. (2019).  Finally, both indicators include an indicator for Complete Vital Registration Statistics (CRVS).  The CRVS indicator is in the administrative data section of the new SPI overall score, while it was in the standards, methods, and classifications section of the SPI version 0.

For the differences, SPI version 0 had four dimensions, namely: (i) Methodology, Standards and Classifications (MSC), which provides information on the technology being used by the NSS; (ii) Census and Surveys (CS), which describes the intermediate products of the NSS; (iii) Availability of Key Indicators (AKI), which focuses on key final products needed for policy; and (iv) Dissemination Practices and Openness (DPO), which evaluates the extent to which products are publicly disseminated. 

The indicator on AKI, from version 0, is conceptually similar to our Data Products dimension in the new SPI, but uses different sources of data and the DPO section is similar to our data services section, but draw on some different sources in some cases.

We compare the SPI overall score to the SPI version 0.  The correlation between the SPI overall score and the version 0 index is `r round(cor(comparison_df$SPI.INDEX,comparison_df$SPI_v0, use='pairwise.complete.obs'),3)`



```{r spiv0, echo=FALSE}


### Scatterplot SPI SPI_v0
spi_spi_plot <- ggplot(comparison_df, aes(y=SPI.INDEX,x=SPI_v0, color=region)) +
  facet_wrap(~date) +
  # geom_point() +
  geom_text(aes(label=iso3c)) +
  theme_bw() +
  labs(
    title='Scatterplot of new SPI overall score on SPI Version 0 Index'
  ) +
  ylab('SPI overall score') +
  xlab('SPI Version 0 value') +
  theme(legend.position = 'bottom')

spi_spi_plot






```

## Other Tables and Figures


```{r gereg, echo=FALSE}
# 





ge_spi <- lm_robust(GE.EST ~ SPI.INDEX + log(NY.GDP.PCAP.KD) + factor(date) + factor(region) , data = ge_df, se_type = "HC2") 

ge_spi_tidy <- broom::tidy(ge_spi)
ge_spi_glance <- broom::glance(ge_spi)

#fix labels
factor_names <- grep("factor", names(coef(ge_spi)), value = TRUE)
names(factor_names) <- gsub(".*)(.)", "\\1", factor_names)


#create table
huxtable::huxreg('Goverment Effectiveness'=ge_spi,
       coefs=c('SPI Overall Score'='SPI.INDEX', 'Log GDP per Capita'='log(NY.GDP.PCAP.KD)', factor_names,  'Intercept'='(Intercept)'),
       note='{stars}. Heteroskedasticity Robust Std Errors in Parenthesis.',
       number_format=3,
       bold_signif=0.05) %>%
  #huxtable::set_caption('Linear Regressions of Changes in Government Effectiveness on Changes in SPI from 2016-19') %>%
  huxtable::as_flextable() %>%
  add_header_lines('Linear Regressions of Government Effectiveness Score on SPI Overall Score from 2016-19') %>%
  FitFlextableToPage() 

```

## Indicator Metadata


```{r metadatatab2}
####
# create table
####

metatable <- metadata %>%
  filter(grepl('SPI.D',source_id)) %>%
  select(-spi_indicator_name,-source_id)



index_tab <- flextable(metatable) %>%
  add_header_lines('SPI Indicator Metadata.') %>%
  set_header_labels(values=list(
                       source_name="Indicator Name",
                       SPI_indicator_id="Pillar",
                       spi_indicator_description="Brief Description",
                       spi_indicator_scoring="Scoring"
                                   ))
  FitFlextableToPage(index_tab) %>%
  width(width=1.63)


```


```{r polar_coordinates, eval=FALSE, fig.height=20, fig.width=20, include=FALSE}

  variables<-'SPI.INDEX'

  title <- metadata_full %>%
    filter(source_id==variables)
  
  title <- title$source_name
    
  SPI_changes <- spi_index_df %>%
    rename(outcome=!!variables) %>%
    select(country,iso3c, date, iso3c,region, outcome) %>%
    filter(!is.na(outcome)) %>%
    pivot_wider(
      names_from='date',
      names_prefix='outcome_',
      values_from='outcome'
      ) %>%
    mutate(change=outcome_2019-outcome_2016,
           color=if_else(change>=0,'improved', 'decreased')) %>%
    arrange(-outcome_2019) %>%
    mutate(country=factor(country, levels=unique(spi_index_df$country)))
  
  p<- ggplot(SPI_changes, aes(x=country)) +
    geom_point(aes(y=outcome_2016)) +
    geom_point(aes(y=outcome_2019), color='blue') +
    geom_segment( aes(x=country ,xend=country, y=outcome_2016, yend=outcome_2019,
                      color=color)) +
    scale_color_manual(values = c('decreased' = "red", 'improved' = "green")) +
    coord_polar() +
    theme_bw() +
    labs(
      title=paste(title, "Change from 2016-2019", sep=" - "),
      subtitle='Source: Statistical Performance Indicators',
      color = 'Change 2016-2019') +
    ylab('SPI Value')
    
  p


```

```{r clusteranalysis, eval=FALSE, fig.height=20, fig.width=20, include=FALSE}
library("factoextra")

cluster_df <- spi_index_df %>%
  filter(date==2019) %>%
  filter(!is.na(SPI.INDEX)) %>%
  select(country, starts_with("SPI.INDEX")) %>%
  column_to_rownames(var='country')

# Enhanced k-means clustering
res.km <- eclust(cluster_df, "kmeans")
fviz_gap_stat(res.km$gap_stat)
km_df<-res.km$clust_plot$data

# Enhanced hierarchical clustering
res.hc <- eclust(cluster_df, "hclust") # compute hclust
fviz_gap_stat(res.hc$gap_stat)
fviz_dend(res.hc, rect = TRUE) # dendrogam
hc_df<-res.hc$cluster %>%
  as_tibble()
```


# References

